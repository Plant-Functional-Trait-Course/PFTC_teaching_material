[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PFTC Teaching Material",
    "section": "",
    "text": "Introduction\nThis book provides the teaching material for the Plant Functional Trait Courses (PFTC).\nThe PFTC courses are an international course with hands-on training in trait-based ecology. For more information about the courses see our course webpage.\nHere we provide teaching material for data collection, curation, analysis, documentation, storage, and reuse. In addition, we show reproducible and transparent workflows to make research more open and available. We cover these topics within the fields of plant functional trait ecology, ecosystem ecology, plant physiology and remote sensing.\n\n\n\n\nFigure 1: Trait data collection during PFTC4 on Svalbard."
  },
  {
    "objectID": "1_courses.html#pftc-7-south-africa",
    "href": "1_courses.html#pftc-7-south-africa",
    "title": "\n1  PFTC Course information\n",
    "section": "\n1.1 PFTC 7 South Africa",
    "text": "1.1 PFTC 7 South Africa\nThe PFTC7 course will be held in the Drakensberg Mountains in South Africa, between the 1st and 19th of December 2023."
  },
  {
    "objectID": "1_courses.html#previouse-courses",
    "href": "1_courses.html#previouse-courses",
    "title": "\n1  PFTC Course information\n",
    "section": "\n1.2 Previouse courses",
    "text": "1.2 Previouse courses\nPreviously, we have held courses in China (PFTC1 and 2), Peru (PFTC3 and 5) as well as on Svalbard (PFTC4) and Norway (PFTC6)."
  },
  {
    "objectID": "5_trait_collection.html#collecting-leaves-in-the-field",
    "href": "5_trait_collection.html#collecting-leaves-in-the-field",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.1 Collecting leaves in the field",
    "text": "2.1 Collecting leaves in the field\nBe careful at all time when working in the experiment and avoid stepping on the experimental plots. Make yourself familiar with the experimental design (check the site maps), and how plot, blocks and sites are marked.\nTo collect plants, go to your plot and use a sitting mat to sit next to the plot. Collect the leaves and minimize disturbing the surroundings as much as possible.\nWe will collect traits in three different locations/experiments:\n\nAt 5-6 sites along an elevational gradient (2000 - 3000 m a.s.l.)\nRangeX project: two sites with ambient and warming using OTCs, with native and novel competitors\n\nThe specific sampling and number of species will vary between the different projects.\nTrait sampling protocol\nThe leaves should be collected from each 1 x 1 m plot or close to it.\nWe aim to collect leaves from the species that make up 80% of the cover in each plot. For each plot we will generate a species list.\nBelow is an example code to generate such a species list:\n\nthreshold &lt;-  80\n\ncover |&gt; \n  select(turfID, species, cover) |&gt; \n  group_by(turfID) |&gt; \n  arrange(turfID, -cover) |&gt; \n  mutate(cumsum = cumsum(cover)) |&gt; \n  filter(cumsum &lt;= threshold)\n\nFor each plot and species find 3 individuals that are spread across the plot to avoid sampling clones. Choose reproductively mature adults with fully expanded leaves (i.e. not seedlings) and healthy-looking leaves (i.e. not grazed, no signs of pathogen or herbivore attack, no discoloration).\nMeasure the height of each individual plant and note down the height on the zip-loc bag (see below).\nCollect 1 leaf from the individual, making sure to include the petiole (Figure 2.2 (a)). If you are uncertain whether something is a leaf vs. leaflet (Figure 2.2 (b)), ask your group leader.\nIf you cannot find 3 individuals of each species, that is ok. After a reasonable search, move on to the next species or plot.\n\n\n\n\n\n(a) Leaf atanomy of a single leaf\n\n\n\n\n\n(b) A leaf with leaflets\n\n\n\nFigure 2.2: Leaf atanomy\n\n\nMeasuring vegetative height of individual plants in the field\nMeasure the vegetative height of the individual plant in the field (Figure 2.3). Vegetative height is the shortest distance between the main photosynthetic tissue on the plant and the ground, excluding any reproductive structure (e.g. buds, flowers or fruits). Leave the plant in it’s natural form and do not stretch the plant if it bends.\nDifferent plants will require different measures of height. Figure 2.3 shows a couple of typical examples. For cushion plants (A), stick a the ruler into the cusion all the way to the ground. For forbs and graminoids (B, D, E) measure the main stem leaves, and do not stretch the leaves (D, F, G ).\n\n\n\n\nFigure 2.3: Different plant types and how to measure height.\n\n\n\nRecord this measurement using legibly numbers (Figure 2.4) on the zip-loc bag (Figure 2.5). Place the leaf/leaves for each individual in a bag with wet paper towels for transfer to lab.\n\n\n\n\nFigure 2.4: The one and only approved way to write numbers!\n\n\n\n\n\n\n\nFigure 2.5: Sticker for Zip-loc bag"
  },
  {
    "objectID": "5_trait_collection.html#preparing-leaves-for-measuring-traits-in-lab",
    "href": "5_trait_collection.html#preparing-leaves-for-measuring-traits-in-lab",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.2 Preparing leaves for measuring traits in lab",
    "text": "2.2 Preparing leaves for measuring traits in lab\nSelect one leaf per individual. For analysing chemical traits such as percent P, C, N and isotopes, a certain amount of dry biomass is needed. Make sure that we are collecting 0.03 g (30 mg) dried leaf material. Otherwise select several leaves until there is enough dry weight. This is called a bulk sample and should be indicated on the envelope (e.g. count the nr of leaves).\nWhen collecting the leaf, include petiole and rachis (Figure 2.2 (b)). Pat the leaf dry with a tissue if there is visible water on the surface. Add a sticker to enter the information and a barcode sticker to the envelope (Figure 2.6 and Figure 2.6 (a)). Attach the sticker with a stapler.\n\n\n\n\n\nLabel with information\n\n\n\n\n\n(a) Barcode with unique leaf ID\n\n\n\nFigure 2.6: Sticker and barcode example.\n\n\n\n\n\n\n\n\nHow IDs and barcodes are generated\n\n\n\nFor more information on how the unique leaf IDs and barcode stickers are generated, see the readme file in this GitHub repo.\n\n\nFill in all information between ‘collection day’ and ‘Bulk nr/length’. Carefully, check Table 2.1 for the different options for the information on the label.\nPlace the leaf inside the envelope and put the envelope in a box for the next step. Make sure the envelopes are kept wet at all times.\n\n\nTable 2.1: Information to write on the envelope.\n\n\n\n\n\n\nVariable\nWhat to fill in\n\n\n\n\n\nGradient\nRangeX\n\n\nDate\nadd day, e.g. 6\nadd day, e.g. 6\n\n\nsiteID\nNumber 1-5\nLS / HS (circle)\n\n\nElevation\n\n-\n\n\nAspect\nEast / West (circle)\n-\n\n\nVegetation\n-\nfocal / native (circle)\n\n\nTreat_1\n-\nambient / warm (circle)\n\n\nTreat_2\n-\nvegetation / bare\n\n\nSpecies (genus and species)\nBistorta vivipara\nBistorta vivipara\n\n\nProject\nT = trait, S = spectroscophy, R = roots, P = photosynthesis\nT = Trait\n\n\nBlockID\n-\nNumber 1-10\n\n\nPlotID\nNumber 1-5\nNumber 1-6\n\n\nPlantID\nNumber 1-3\n-\n\n\nPositionID\n-\nNumber 1-12\n\n\nLeafID\n-\n-\n\n\nHeight cm\nNumber\nNumber\n\n\nBulk nr\nNumber if multiple leaves were samples\nNumber if multiple leaves were samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning for special cases.\n\n\n\nCarefully check the rules for how to measure special plant species plants.\n\n\nxx sp have tightly rolled leaves and they should not be unfolded for the scanning.\n\nxx sp have tiny leaves. Choose a 10 cm piece of stem and scrape of all the leaves from this part for scanning. Make sure the leaves do not overlap"
  },
  {
    "objectID": "5_trait_collection.html#wet-mass",
    "href": "5_trait_collection.html#wet-mass",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.3 Wet mass",
    "text": "2.3 Wet mass\nMake sure the envelopes are still kept wet. Weigh each leaf and write the weight on the envelope, including all digits."
  },
  {
    "objectID": "5_trait_collection.html#measure-leaf-area-using-a-scanner",
    "href": "5_trait_collection.html#measure-leaf-area-using-a-scanner",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.4 Measure leaf area using a scanner",
    "text": "2.4 Measure leaf area using a scanner\nFor scanning the leaves we are using a Rasperry Pi setup. The Pis control the scanners, ensuring consistency, and validate file names.\n\n\n\n\n\n\nRaspberry Pi setup\n\n\n\nFor more information on the Raspberry Pi setup, see the readme file in this GitHub repo.\n\n\nStart setup\nConnect your Laptop to the Raspberry PI. Connect the PI with an ethernet cable to your laptop. Connect the scanner to the PI. Connect the barcode scanner to the PI. Connect the power cable to the PI.\nWait for one minute.\nOpen VNC Viewer and type in the IP address corresponding to your PI (Table 2.2).\n\n\nTable 2.2: IP addresses of the PIs.\n\nPI\nIP address\n\n\n\nobi wan\n169.254.109.180\n\n\nyoda\n169.254.160.193\n\n\nbb-8\n169.254.54.188\n\n\nc-3po\n169.254.247.22\n\n\ndarth vader\n169.254.178.187\n\n\nr2-d2\n169.254.231.2\n\n\ndeathstar\n169.254.152.80\n\n\nmr. spock\n169.254.204.207\n\n\nGrogu\n169.254.169.194\n\n\nPrincess Leia\n169.254.128.185\n\n\nRey\n169.254.217.147\n\n\nKylo Ren\n169.254.77.108\n\n\n\n\n\n\nconnect with phone\n192.168.42.42\n\n\n\n\nThe spare SD card has the same IP address as the pi it is in!\nYou will be asked to type in a username and password:\nUsername: pi\nPassword: pftc\nResize the screen for convenience.\nIf the pi goes in terminal mode, then type xstart + enter to run the desktop.\nScan leaves\nMake sure the envelopes are still kept wet. Check that the scanner is clean and free of debris. Clean if needed. Place wet leaf face-down on the scanner. Make sure the leaf is not folded and that leaflets do not overlap. The leaf should not go all the way to the edge of the scanner, because each picture will be cropped. You can cut the leaf into several pieces if needed, but please make a remark if you do so (e.g. cut 3). You can tape the leaf to the scanner using transparent tape if it folds (e.g. grasses).\nFor graminoids (grasses, sedges, rushes): Spread graminoid blades flat and tape to scanner if necessary to hold them in place. Exclude the leaf sheath (Figure 2.7).\n\n\n\n\nFigure 2.7: Leaf blade and sheats for a graminoid\n\n\n\n\n\n\n\n\n\nSpecial cases for scanning\n\n\n\nCarefully check the rules for how to scan special plant species plants.\n\n\nFestuca sp have tightly rolled leaves and they should not be unfolded for the scanning.\n\n\n\nScan, save and check the leaf\nClick on the leaf icon (only needs to be done the first time). This will start the scanning program. If the scanner cannot be found, wait for a bit and try again. A window might pop up and you have to select the scanner. Choose the first option. Check the settings of the scanner. These should be set as standard, so please do not touch them if not needed.\nThe scanner settings should be:\n\nsaved in Desktop/leaf_scans/\nType: JPEG\nColour\nFull colour range\n300dpi\n\nFrom here, do this for each leaf:\nPress scan (at the bottom of the window) and wait a couple of seconds until the scanning process is done. A new window will pop up. Adjust the zoom to see the full picture (about 25%). Check the quality of the scan (has the whole leaf been scanned, is the leaf not upside down, dirt on the scan, etc.). If the scan is not ok, adjust the leaf and repeat the scan.\nWhen the scan is ok, click on the green save button to save the scan. Make sure the cursor marks the filename (should be default). Scan the barcode on the envelope of the leaf that has been scanned with the barcode reader. The filename should be something like: AAA4667 (3 letters and 4 digits). When the scan is saved, the PI will check that the LeafID and that the scanning settings (dpi, etc.) are correct. If anything is wrong, it will open a window with an error message (Figure 2.8). Please read it!\n\n\n\n\nFigure 2.8: Error message on the PI.\n\n\n\nClick anywhere in the window and it will disappear. Save the scan with the correct name or scan the leaf again if the settings are wrong. MAKE SURE TO DELETE THE SCAN WITH THE WRONG NAME OR SETTING. Tick the box on the envelope that the leaf has been scanned. Make sure the scanned leaves are kept wet and move them to the next station.\nFrom time to time:\nWhen you are finished with scanning click on the yoda icon. This will check the leafIDs. If anything is wrong it will open a window and indicate which scans are wrong. Make sure to fix all the wrong leafIDs and not to have duplicate scans before leaving the station.\nBefore leaving the station:\nCopy all the scans onto a stick and deposit them on the PFTC6 hard drive. Shut down the pi. Wait 1 min to disconnect it from the power."
  },
  {
    "objectID": "5_trait_collection.html#leaf-thickness",
    "href": "5_trait_collection.html#leaf-thickness",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.5 Leaf thickness",
    "text": "2.5 Leaf thickness\nMake sure the envelopes are still kept wet. Thickness varies over the surface of the leaf; generally, the leaf is thickest at the midrib, primary veins, margins, and leaf base. Avoid the midrib when measuring leaf thickness, unless the leaf is too small (Figure 2.9). Take three thickness measurements at several points on the lamina and note them on the envelope. From this, we will later calculate the average thickness. If the leaf is small, it may not be possible to take three unique measurements.\n\n\n\n\nFigure 2.9: Showing where leaf thickness can be measured and where not, e.g. the midrib.\n\n\n\nFerns Make sure you do not measure thickness on the spore-producing sori on the backside of ferns."
  },
  {
    "objectID": "5_trait_collection.html#data-entry",
    "href": "5_trait_collection.html#data-entry",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.6 Data entry",
    "text": "2.6 Data entry\nIdeally the envelope should still be kept wet until this point in case any information is missing. Go to this google sheet. Connect a barcode scanner to your computer. Scan the barcode of an envelope. Make sure that your cursor is in the right cell (ID). Enter all the data that is on the envelope (for details see Table 2.1). If any of the information is missing, check if it has been forgotten. Has the leaf been scanned, one thickness measurement is missing, etc. If anything is missing bring the leaf back to the according station in the trait wheel. When finished, check the box on the envelope that the data has been entered. Take a picture of the envelope. Bring the envelop to the drying station."
  },
  {
    "objectID": "5_trait_collection.html#dry-mass",
    "href": "5_trait_collection.html#dry-mass",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.7 Dry mass",
    "text": "2.7 Dry mass\nThe leaves will be dried in the oven for 72 hours at 65°C."
  },
  {
    "objectID": "5_trait_collection.html#data-checking",
    "href": "5_trait_collection.html#data-checking",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.8 Data checking",
    "text": "2.8 Data checking\nCheck scans Find the folder with the leave scans on google drive: link Open each scan and check the follwing criterias:\n\nIs the whole leaf on the scan?\nHas nothing else been scanned (cable, paper,…)?\nIs there dirty the scan?\nHas the leaf been cut? If yes, is it indicated on the envelope?\nHow many leaves are on the scan? If &gt; 1 is there a remark on the envelope?\n\nCheck data Open RStudio project and the R script (…). Download the trait data from google sheet. Check if the leafID is valid. Check if the variables have valid entries. E.g. correct day, site name, elevations, etc. Check if missing values can be found on the envelope or retrieved from the data. Plot the data to check if traits have unrealistic values. For more details see section data curation."
  },
  {
    "objectID": "5_trait_collection.html#data-documentation",
    "href": "5_trait_collection.html#data-documentation",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.9 Data documentation",
    "text": "2.9 Data documentation\n\ndescription of the method of data collection\ndata dictionary for each data set"
  },
  {
    "objectID": "5_trait_collection.html#references",
    "href": "5_trait_collection.html#references",
    "title": "\n2  The trait wheel\n",
    "section": "\n2.10 References",
    "text": "2.10 References\n\n\n\n\nPérez-Harguindeguy, N, S Dı́az, E Garnier, S Lavorel, H Poorter, P Jaureguiberry, M S Bret-Harte, et al. 2013. “New Handbook for Standardised Measurement of Plant Functional Traits Worldwide.” Australian Journal of Botany."
  },
  {
    "objectID": "6_pftc_data.html#pftc-data-repositories",
    "href": "6_pftc_data.html#pftc-data-repositories",
    "title": "3  Working with PFTC data",
    "section": "\n3.1 PFTC data repositories",
    "text": "3.1 PFTC data repositories\nThe cleaned datasets from the PFTC courses are stored on an OSF repository (short repo). Each course has it’s own data repo. The following table shows the link to each of the repos.\n\n\nCourse\nCountry\nData repo\n\n\n\nPFTC1 and 2\nChina\nChina repo\n\n\nPFTC3 and 5\nPeru\nPeru repo\n\n\nPFTC4\nSvalbard\nSvalbard repo\n\n\nPFTC6\nNorway\n3D repo\n\n\n\n\nIncline repo"
  },
  {
    "objectID": "6_pftc_data.html#data-paper-and-data-documentation",
    "href": "6_pftc_data.html#data-paper-and-data-documentation",
    "title": "3  Working with PFTC data",
    "section": "\n3.2 Data paper and data documentation",
    "text": "3.2 Data paper and data documentation\nThe site, experiment, data collection methods and data dictionaries for each course are described in data papers. Some information can also be found on the GitHub readme file.\n\n\nCourse\nCountry\nData paper/documentation\n\n\n\nPFTC1 and 2\nChina\nData paper\n\n\nPFTC3 and 5\nPeru\nGitHub readme\n\n\nPFTC4\nSvalbard\nGitHub readme\n\n\nPFTC6\nNorway\n3D: GitHub readme\n\n\nPFTC6\nNorway\nIncline: GitHub readme\n\n\n\nRead the papers and documentation carefully before using the data."
  },
  {
    "objectID": "6_pftc_data.html#data-usage-and-citation",
    "href": "6_pftc_data.html#data-usage-and-citation",
    "title": "3  Working with PFTC data",
    "section": "\n3.3 Data usage and citation",
    "text": "3.3 Data usage and citation\nThe data are available for use and teaching purposes under a CC-BY licence. We suggest to cite the data paper if available, or alternatively the OSF repo. We appreciate being contacted for advice or collaboration, if relevant, by users of these data. In cases where our data make up &gt;10% of the data used in a downstream publication, we suggest contacting us for our contribution and collaboration."
  },
  {
    "objectID": "6_pftc_data.html#download-pftc-data",
    "href": "6_pftc_data.html#download-pftc-data",
    "title": "3  Working with PFTC data",
    "section": "\n3.4 Download PFTC data",
    "text": "3.4 Download PFTC data\nWe have created a R package to download the data, called dataDownloader. If you are using the package for the first time you need to install the package using the command below. If you have used it before, just run the second line of code to load the package.\n\ndevtools::install_github(\"Between-the-Fjords/dataDownloader\")\nlibrary(dataDownloader)\n\nNow you can download the all the files you need. Let’s download the community data and the trait from the Svalbard course.\n\nget_file(node = \"smbqh\",\n         file = \"PFTC4_Svalbard_2018_Gradient_Traits.csv\",\n         path = \"webpage/data\",\n         remote_path = \"Traits\")\n                       \nget_file(node = \"smbqh\",\n         file = \"PFTC4_Svalbard_2018_Community_Gradient.csv\",\n         path = \"webpage/data\",\n         remote_path = \"Community\")\n\nExercise\nNow it is your turn. Copy the code into your console and download the data."
  },
  {
    "objectID": "7_biostats.html",
    "href": "7_biostats.html",
    "title": "\n4  Introduction to R, RStudio and GitHub\n",
    "section": "",
    "text": "The BioSTATS books are an extensive resource for getting started with R and RStudio, working in R, coding, using Rmarkdown, git and GitHub and creating an R package."
  },
  {
    "objectID": "8_reproducible.html",
    "href": "8_reproducible.html",
    "title": "\n5  Reproducible workflows\n",
    "section": "",
    "text": "Reproduciblitiy …"
  },
  {
    "objectID": "9_data_curation.html#useful-packages",
    "href": "9_data_curation.html#useful-packages",
    "title": "6  Data curation",
    "section": "\n6.1 Useful packages",
    "text": "6.1 Useful packages\nThere are a couple of R packages that are useful for data curation. First, tidyverse is a collection of R packages used for basic data manipulation and analysis. We will also use lubridate, which helps with data and time formats.\nIf you have never used the packages you need to install it first using the function install.packages(\"tidyverse\"). Otherwise, you can just load the packages.\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\nAnother useful package for data curation is tidylog, which is built on the dplyr and tidyr packages and provides useful information about the functions used.\nTidylog will for example tell you how many rows have been removed and are remaining when using the filter() function or how many rows match when using a join function. The information is always indicated in absolute numbers and percentage. This additional information is very useful to check if the right observations have been removed or manipulated, because mistakes are easily done.\nLet’s install and/or load tidylog.\n\nlibrary(tidylog)\n\nNote, that once tidylog is loaded it will automatically prioritize the tidylog function before the dplyr and tidyr functions. You actively have to choose if you do not want to use the tidylog version by using this notation: dplyr::filter().\nSome data checking has to be done by hand and detecitve work, other things can be done more automatically. There are a few packages that can help with some of this work and for this tutorial we will use the validate package.\n\n#install.packages(\"validate\")\nlibrary(validate)"
  },
  {
    "objectID": "9_data_curation.html#import-data",
    "href": "9_data_curation.html#import-data",
    "title": "6  Data curation",
    "section": "\n6.2 Import data",
    "text": "6.2 Import data\nThe first step is to import the dataset to R. The data is stored as a csv file and we can use the function read_csv() to import that data. If your data has another format or you are new to importing data, have a look at this page.\nGive the dataset a name using a backwards pointing arrow: &lt;- The name should indicate that this is the raw data.\n\nraw_traits &lt;- read_csv(\"data/PFTC4_Svalbard_2018_Gradient_Traits.csv\")\n#&gt; Rows: 11345 Columns: 15\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (7): Project, Gradient, PlotID, ID, Functional_group, Taxon, Trait\n#&gt; dbl  (7): Year, Site, Individual_nr, Value, Elevation_m, Latitude_N, Longitu...\n#&gt; date (1): Date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThe dataset has 11345 rows and 15 columns and a number of numeric, character and date variables. It contains measurements of 14 traits from two elevational gradients on Svalbard. The traits were measured on individual plants from 21 different graminoid and forb species. For more information about the sites, traits and measurements see here.\nSome manipulation\nLet us introduce some errors to the dataset.\nThe code to do this is hidden. But if you want to replicate the code to introduce errors you can find the code from line 116."
  },
  {
    "objectID": "9_data_curation.html#view-dataset",
    "href": "9_data_curation.html#view-dataset",
    "title": "6  Data curation",
    "section": "\n6.3 View dataset",
    "text": "6.3 View dataset\nFirst, we want to have a look at the dataset. By typing raw_traits in the console it will display the first rows and columns of the dataset. Note that the last column and many rows are not shown.\n\nraw_traits\n#&gt; # A tibble: 10,298 × 10\n#&gt;    Date       Gradient  Site PlotID Individual_nr ID      Taxon    Trait   Value\n#&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;\n#&gt;  1 2018-07-20 B            5 D                  1 AIB1395 saxifra… Plan… 6.5 e+0\n#&gt;  2 2018-07-20 B            5 D                  1 AIB1395 saxifra… Wet_… 2.92e-2\n#&gt;  3 2018-07-20 B            5 D                  1 AIB1395 saxifra… Dry_… 4   e-3\n#&gt;  4 2018-07-20 B            5 D                  1 AIB1395 saxifra… Leaf… 5.66e-1\n#&gt;  5 2018-07-20 B            5 D                  1 AIB1395 saxifra… Leaf… 6.75e-1\n#&gt;  6 2018-07-20 B            5 D                  1 AIB1395 saxifra… SLA_… 1.69e+2\n#&gt;  7 2018-07-20 B            5 D                  1 AIB1395 saxifra… LDMC  1.37e-1\n#&gt;  8 2018-07-20 B            5 D                  1 AIB1395 saxifra… C_pe… 3.89e+1\n#&gt;  9 2018-07-20 B            5 D                  1 AIB1395 saxifra… N_pe… 1.14e+0\n#&gt; 10 2018-07-20 B            5 D                  1 AIB1395 saxifra… CN_r… 3.41e+1\n#&gt; # ℹ 10,288 more rows\n#&gt; # ℹ 1 more variable: Elevation_m &lt;dbl&gt;\n\nAt the top you can see that the dataset has 10298 observations and 10 columns. These numbers give you a first indication if you have imported the right dataset, and if all observations and columns are there."
  },
  {
    "objectID": "9_data_curation.html#check-variable-type",
    "href": "9_data_curation.html#check-variable-type",
    "title": "6  Data curation",
    "section": "\n6.4 Check variable type",
    "text": "6.4 Check variable type\nOne of the things we want to do is checking if all the variables in the dataset have the right type. For each variable the output above indicates the data type just below the variable name. The most common types are dbl (numeric or integer), chr (character), or date (date).\nIf you are unfamiliar with data types see here.\nThe first variable Date is a character, which does not seem to be correct. This means that one or several observations in this column are not dates. Since we do not expect to have very many dates (the data was collected during a few days), we can check all the different values in Date. For this we use the function distinct() on the variable Date.\n\nraw_traits |&gt; \n  distinct(Date)\n#&gt; distinct: removed 10,291 rows (&gt;99%), 7 rows remaining\n#&gt; # A tibble: 7 × 1\n#&gt;   Date      \n#&gt;   &lt;chr&gt;     \n#&gt; 1 2018-07-20\n#&gt; 2 2018-07-18\n#&gt; 3 2018-07-21\n#&gt; 4 2018-07-19\n#&gt; 5 2018-07-17\n#&gt; 6 18        \n#&gt; 7 &lt;NA&gt;\n\nWe see that there are 6 distinct dates in the variable Date. One of the dates is “18”, which is not a correct date format and turned the variable into a character. Note the additional information from the tidylog package on the distinct() function, which shows the number of rows removed and remaining.\nThe next step is to check which observastion(s) have the wrong date. For this we can use the function filter() to extract all observations with the date 18. We can pipe this to View(), which will display the whole table in a separate window. Note that for this tutorial, we use a different way of displaying the output\n\nraw_traits |&gt; \n  filter(Date == \"18\") |&gt; \n  View()\n\n\n#&gt; filter: removed 10,291 rows (&gt;99%), 7 rows remaining\n#&gt; # A tibble: 7 × 10\n#&gt;   Date  Gradient  Site PlotID Individual_nr ID      Taxon         Trait    Value\n#&gt;   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 18    C            1 A                  3 AMO3822 salix polaris Plant… 1.1 e+0\n#&gt; 2 18    C            1 A                  3 AMO3822 salix polaris Wet_M… 5.76e-3\n#&gt; 3 18    C            1 A                  3 AMO3822 salix polaris Dry_M… 2   e-3\n#&gt; 4 18    C            1 A                  3 AMO3822 salix polaris Leaf_… 1.88e-1\n#&gt; 5 18    C            1 A                  3 AMO3822 salix polaris Leaf_… 2.84e-1\n#&gt; 6 18    C            1 A                  3 AMO3822 salix polaris SLA_c… 1.42e+2\n#&gt; 7 18    C            1 A                  3 AMO3822 salix polaris LDMC   3.47e-1\n#&gt; # ℹ 1 more variable: Elevation_m &lt;dbl&gt;\n\nWe can see that a single observation (with multiple traits) has the wrong date. There is no way that we would remember on what day this leaf was collected (remember the dataset has &gt; 10000 leaves!). We have to start playing detectives now. The only way to find the right date for these observations is to check the raw data (leaves), notes or photos. It is therefore important to keep all the data entry sheets (paper version), take a photo of them and make tidy notes during field work. This is the only way to fix many of the problems.\nLuckily, we took pictures from all envelopes of the leaves. The date on the envelope is 18 July 2018 (Figure 6.1), and it seems that there has been a typo.\n\n\n\n\nFigure 6.1: The envelope of the leaf with the wrong date.\n\n\n\nLet’s replace the wrong date and give the variable Date the right class.\nFor this we will use the function mutate() which adds or manipulates a column. Inside the mutate we will use the if_else() function to replace the date for a specific ID. This function is useful for a single condition. However for multiple statements (many if else conditions), we recommend to use the case_when() function (see below). To change the class, we use the ymd() function from the lubridate package. Note that we now have to assign the table to a new or the same name to make the change permanent.\n\nraw_traits &lt;- raw_traits |&gt; \n  mutate(Date = if_else(ID == \"AMO3822\", \"2018-07-18\", Date)) |&gt; \n  mutate(Date = ymd(Date))\n#&gt; mutate: changed 7 values (&lt;1%) of 'Date' (0 new NA)\n#&gt; mutate: converted 'Date' from character to Date (0 new NA)\n\nAn important step and good practice when cleaning data is to check that the right correction has been done. Here is where the tidylog package comes in handy. It shows that for 7 observation Date has been changed. This matches with the number of observations that had a wrong date.\nTo be absolutely sure we can look at the specific leaf (ID == “AMO3822”) and see if the date is now corrected. Another way would be to run the distinct(Date) function again.\n\nraw_traits |&gt; \n  filter(ID == \"AMO3822\") |&gt; \n  select(Date)\n#&gt; filter: removed 10,291 rows (&gt;99%), 7 rows remaining\n#&gt; select: dropped 9 variables (Gradient, Site, PlotID, Individual_nr, ID, …)\n#&gt; # A tibble: 7 × 1\n#&gt;   Date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2018-07-18\n#&gt; 2 2018-07-18\n#&gt; 3 2018-07-18\n#&gt; 4 2018-07-18\n#&gt; 5 2018-07-18\n#&gt; 6 2018-07-18\n#&gt; 7 2018-07-18\n\nThe date has been fixed.\n\n\n\n\n\n\nExercise 1\n\n\n\nNow it is your turn. Check if the data type for the variable Date is now correct.\nHint\n\ntype raw_traits to look at the whole dataset where the datatype of each variable is indicated\nuse class(raw_traits$Date) which will tell you directly what type of class the variable has\nuse map(raw_traits, class) to get the class of all variable in the dataframe\n\n\n\nUsing the validate package, we can check all the variables at once. The validate package is based on making some rules that need checking and then applying those rules to a dataset. The rules can be reused and applied to any dataset.\nLet’s make some rules about data types using the validator() function:\n\n# rules\nrules &lt;- validator(\n  \n  # check variable types\n  is.character(Gradient),\n  is.character(PlotID),\n  is.character(ID),\n  is.character(Taxon),\n  is.character(Trait),\n\n  is.numeric(Site),\n  is.numeric(Individual_nr),\n  is.numeric(Value),\n  is.numeric(Elevation_m),\n  \n  is.Date(Date))\n\nNow the rules can be applied to the dataset using the confront() function.\n\nout &lt;- confront(raw_traits, rules)\nsummary(out)\n  \n\nThe summary function gives an overview of each rule and how many passes and fails there are. It looks like all the rules are passed."
  },
  {
    "objectID": "9_data_curation.html#check-for-duplicates",
    "href": "9_data_curation.html#check-for-duplicates",
    "title": "6  Data curation",
    "section": "\n6.5 Check for duplicates",
    "text": "6.5 Check for duplicates\nAnother common problem is duplicate observations. This can happen when data is entered twice. The why to find duplicates is to check that the combination of variables are unique. In our dataset, we expect that Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon and Trait should be unique, and only occurring once.\nTo check this, we can use the rule is_unique().\nNote that Value was not included in the is_unique(). This was done intentionally, because a common mistake is to have a duplicate, but with a different value. This is either because one of the variables is wrong, e.g. it has the wrong Site and therefore appears to be a duplicate. Alternatively, the leaf could have been measured twice by accident, which would likely give two slightly different values. When getting a duplicate, these different options for why there is a duplicate have to be considered and carefully checked in the raw data.\n\nrules &lt;- validator(\n  \n  # check variable types\n  is_unique(Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon, Trait))\n\nout &lt;- confront(raw_traits, rules)\nsummary(out)\n#&gt;   name items passes fails nNA error warning\n#&gt; 1   V1 10298  10296     2   0 FALSE   FALSE\n#&gt;                                                                 expression\n#&gt; 1 is_unique(Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon, Trait)\n\nTwo observations fail the rules and are not unique.\nThe violate package can visualise the number of passes and fails, which can be useful. For this, use the plot function.\n\nplot(out)\n\n\n\nA plot showing the fails and passes. Note that there are very few fails compared to passes and the red bar is not visible on the plot.\n\n\n\nTo fix the problem, we need to know which observation is a duplicate. Here, we can use the function violating() for the data and the results and it will show the duplicate rows.\n\nviolating(raw_traits, out)\n#&gt; # A tibble: 2 × 10\n#&gt;   Date       Gradient  Site PlotID Individual_nr ID      Taxon     Trait   Value\n#&gt;   &lt;date&gt;     &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 2018-07-20 B            3 C                  3 BEK3638 salix po… Dry_… 0.00275\n#&gt; 2 2018-07-20 B            3 C                  3 BEK3638 salix po… Dry_… 0.00275\n#&gt; # ℹ 1 more variable: Elevation_m &lt;dbl&gt;\n\nWe get two exact duplicates, where even Value is the same. We can therefore assume that the leaf has only been measured once, but the data has been entered twice.\nTo fix the problem, we want to remove one of the duplicates. We group by the variables we expect to be unique and use distinct() with the argument .keep_all = TRUE to remove the duplicates.\n\nraw_traits &lt;- raw_traits |&gt; \n  group_by(Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon, Trait) |&gt; \n  distinct(.keep_all = TRUE) |&gt; \n  ungroup()\n#&gt; group_by: 8 grouping variables (Date, Gradient, Site, PlotID, Individual_nr, …)\n#&gt; distinct (grouped): removed one row (&lt;1%), 10,297 rows remaining\n#&gt; ungroup: no grouping variables\n\nTidylog shows again what happens and how many rows have been removed. There are 8 grouping variables and as expected, one row is removed, which is the duplicated row.\nWe can also run the code from above again to check if the duplicate is gone."
  },
  {
    "objectID": "9_data_curation.html#check-for-missing-data",
    "href": "9_data_curation.html#check-for-missing-data",
    "title": "6  Data curation",
    "section": "\n6.6 Check for missing data",
    "text": "6.6 Check for missing data\nA common problem in a dataset are missing data. There are many reasons for having missing data. For now, we want to find out if we have any NAs in the dataset and if yes where and how many.\nA quick way to get an overview of all NAs in the dataset is to select for any NAs in the dataset and summarise how many NAs there are.\n\nraw_traits %&gt;% \n  select(where( ~any(is.na(.)))) %&gt;% \n  summarise(across(everything(), ~sum(is.na(.))))\n#&gt; select: dropped 8 variables (Gradient, Site, PlotID, Individual_nr, ID, …)\n#&gt; summarise: now one row and 2 columns, ungrouped\n#&gt; # A tibble: 1 × 2\n#&gt;    Date Value\n#&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1     7     3\n\nThe variables Date and Value have NAs. It is not always a problem to have missing data. In this case, Date is not a crucial variable, and we know the data was collected during a few days in July 2018. We could just impute one of these dates. But for now, let’s focus on the NAs in Value.\nOnce the missing values are detected one has to decide if the missing data can be recovered, or if the missing values should be removed from the dataset. After checking all the raw data and notes, we cannot find the Values from these observations and have to conclude that the data is useless. So, we want to remove them. For this we will use the function drop_na() on the variable Value.\n\nraw_traits &lt;- raw_traits |&gt; \n  drop_na(Value)\n#&gt; drop_na: removed 3 rows (&lt;1%), 10,294 rows remaining\n\nThis operation has removed 3 rows, which is the number of NA’s in this variable.\nMissing data can also be detected using the validator package. It is however more tedious to write one rule (is.na() or !is.na()) for each variable. But it can also be useful, because the is.na() function can be combined with any() or all(), defining to include/exclude some or all NAs in a variable."
  },
  {
    "objectID": "9_data_curation.html#check-range-of-values",
    "href": "9_data_curation.html#check-range-of-values",
    "title": "6  Data curation",
    "section": "\n6.7 Check range of values",
    "text": "6.7 Check range of values\nSome variables might have specific values we want to check. For categorical variables there is usually a list of specific values to test, while for numeric variables, it is more common to have a range of values or upper/lower limits.\n\n6.7.1 Categorical variables\nLet’s look at the variable leaf ID, where we have a list of valid values. For this, we need to get a list of valid IDs, using the get_PFTC_envelope_codes function from the PFTCFunctions package.\n\n#remotes::install_github(\"Plant-Functional-Trait-Course/PFTCFunctions\")\n\nlibrary(\"PFTCFunctions\")\n\nleaf_ID &lt;- get_PFTC_envelope_codes(seed = 32)\n\nLet’s make some rules to check the variables Gradient, Site and leaf_ID.\n\n# rules\nrules &lt;- validator(\n  Gradient %in% c(\"B\", \"C\"),\n  Site %in% c(1:7),\n  ID %in% c(leaf_ID$hashcode))\n\nAnd then check the rules in the dataset.\n\nout &lt;- confront(raw_traits, rules)\nsummary(out)\n#&gt;   name items passes fails nNA error warning                        expression\n#&gt; 1   V1 10294  10294     0   0 FALSE   FALSE        Gradient %vin% c(\"B\", \"C\")\n#&gt; 2   V2 10294  10294     0   0 FALSE   FALSE                 Site %vin% c(1:7)\n#&gt; 3   V3 10294  10280    14   0 FALSE   FALSE ID %vin% c(leaf_ID[[\"hashcode\"]])\n\nThere are 14 rows with a wrong leaf ID.\n\nviolating(raw_traits, out)\n#&gt; # A tibble: 14 × 10\n#&gt;    Date       Gradient  Site PlotID Individual_nr ID      Taxon   Trait    Value\n#&gt;    &lt;date&gt;     &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1 2018-07-21 B            1 A                  2 BGB8422 salix … Plan…   0.7   \n#&gt;  2 2018-07-21 B            1 A                  2 BGB8422 salix … Wet_…   0.0132\n#&gt;  3 2018-07-21 B            1 A                  2 BGB8422 salix … Dry_…   0.0028\n#&gt;  4 2018-07-21 B            1 A                  2 BGB8422 salix … Leaf…   0.267 \n#&gt;  5 2018-07-21 B            1 A                  2 BGB8422 salix … Leaf…   0.538 \n#&gt;  6 2018-07-21 B            1 A                  2 BGB8422 salix … SLA_… 192.    \n#&gt;  7 2018-07-21 B            1 A                  2 BGB8422 salix … LDMC    0.212 \n#&gt;  8 2018-07-21 B            1 A                  2 BGB8422 salix … C_pe…  47.0   \n#&gt;  9 2018-07-21 B            1 A                  2 BGB8422 salix … N_pe…   3.27  \n#&gt; 10 2018-07-21 B            1 A                  2 BGB8422 salix … CN_r…  14.4   \n#&gt; 11 2018-07-21 B            1 A                  2 BGB8422 salix … dN15…   4.41  \n#&gt; 12 2018-07-21 B            1 A                  2 BGB8422 salix … dC13… -31.8   \n#&gt; 13 2018-07-21 B            1 A                  2 BGB8422 salix … P_pe…   0.213 \n#&gt; 14 2018-07-21 B            1 A                  2 BGB8422 salix … NP_r…  15.3   \n#&gt; # ℹ 1 more variable: Elevation_m &lt;dbl&gt;\n\nThe ID BGB8422 does not exist in the list of valid leaf IDs. There might be a typo in this ID. One thing is to search for the letter or number combinations and see if we can figure out where the mistake happened. For this we will use the stringr package, which is part of tidyverse.\nWith the function str_detect() we can search for specific strings like “BGB” or “8422” in the variable hashcode.\n\nleaf_ID |&gt; \n  filter(str_detect(hashcode, \"8422\"))\n#&gt; filter: removed 17,575 rows (&gt;99%), one row remaining\n#&gt; # A tibble: 1 × 1\n#&gt;   hashcode\n#&gt;   &lt;chr&gt;   \n#&gt; 1 BGP8422\n\nWhen searching for the combinations of numbers, we find a ID that is very similar but a B is replaced by the P. This seems like a mistake that could be easily made. The envelope of this sample should also be checked before fixing the error.\n\n\n\n\n\n\nExercise 2\n\n\n\nLet’s fix the wrong leaf ID, by replacing BGB8422 with BGP8422.\nHint\n\nuse if_else()\n\n\n\n\n\n6.7.2 Numeric variables\nFor numeric variables we could use another set of rules. For example the variable LDMC (Leaf dry matter content) is the dry mass divided by the wet mass. If LDMC is larger than 1 it means that the dry leaf was heavier than the wet leaf, which does not make sense. So, a simple rule to test is that LDMC is between 0 and 1.\nFor this you could just use Value &lt;= 1. But because we have different traits, we need to use a conditional rule:\n\n# rules\nrules &lt;- validator(\n  if (Trait == \"LDMC\") Value &lt;= 1)\n\nAnd then check the rules in the dataset.\n\nout &lt;- confront(raw_traits, rules)\nsummary(out)\n#&gt;   name items passes fails nNA error warning\n#&gt; 1   V1 10294  10294     0   0 FALSE   FALSE\n#&gt;                               expression\n#&gt; 1 Trait != \"LDMC\" | (Value - 1 &lt;= 1e-08)\n\nNone of the values is violating the rules, so all is good."
  },
  {
    "objectID": "9_data_curation.html#check-taxonomy",
    "href": "9_data_curation.html#check-taxonomy",
    "title": "6  Data curation",
    "section": "\n6.8 Check taxonomy",
    "text": "6.8 Check taxonomy\nA common problem is inconsistencies within variables. In this dataset such a variable is Taxon. It is very common to make mistakes and typos with Latin species names during data entry.\nLet’s look at all unique species names using distinct() and sort them by Taxon using arrange(). This is a good way to see small typos in the species names.\n\nraw_traits |&gt; \n  distinct(Taxon) |&gt; \n  arrange(Taxon) |&gt; \n  print(n = Inf)\n#&gt; distinct: removed 10,259 rows (&gt;99%), 35 rows remaining\n#&gt; # A tibble: 35 × 1\n#&gt;    Taxon                   \n#&gt;    &lt;chr&gt;                   \n#&gt;  1 alopecurus ovatus       \n#&gt;  2 bistorta vivipara       \n#&gt;  3 calalmagrostis neglecta \n#&gt;  4 calamagrostis neglecta  \n#&gt;  5 cassiope tetragona      \n#&gt;  6 cerastium arcticum      \n#&gt;  7 draba arctica           \n#&gt;  8 draba oxycarpa          \n#&gt;  9 dryas octopetala        \n#&gt; 10 equisetum arvense       \n#&gt; 11 equisetum scirpoides    \n#&gt; 12 festuca rubra           \n#&gt; 13 festuca viviparoidea    \n#&gt; 14 luzula confusa          \n#&gt; 15 luzula nivalis          \n#&gt; 16 micranthes hieraciifolia\n#&gt; 17 micranthes nivalis      \n#&gt; 18 oxiria digyna           \n#&gt; 19 oxyra digyna            \n#&gt; 20 oxyria digina           \n#&gt; 21 oxyria digyna           \n#&gt; 22 pedicularis hirsuta     \n#&gt; 23 poa alpina              \n#&gt; 24 poa arctica             \n#&gt; 25 poa pratensis           \n#&gt; 26 potentilla hyparctica   \n#&gt; 27 ranunculus sulphureus   \n#&gt; 28 salix polaris           \n#&gt; 29 saxifraga cernua        \n#&gt; 30 saxifraga cespitosa     \n#&gt; 31 saxifraga hirculus      \n#&gt; 32 saxifraga oppositifolia \n#&gt; 33 silene acaulis          \n#&gt; 34 stellaria longipes      \n#&gt; 35 trisetum spicatum\n\nThere are four different versions for oxyra digyna and two for calamagrostis neglecta. Obviously, some typos where made when entering the data.\n\n6.8.1 Use case_when()\nBecause we have to change multiple species names, we will use case_when(), which allows for multiple conditions.\n\nraw_traits &lt;- raw_traits |&gt; \n  mutate(Taxon = case_when(Taxon %in% c(\"oxiria digyna\", \n                                        \"oxyria digina\", \n                                        \"oxyra digyna\") ~ \"oxyria digyna\",\n                           Taxon == \"calalmagrostis neglecta\" ~ \"calamagrostis neglecta\",\n                           TRUE ~ Taxon))\n#&gt; mutate: changed 38 values (&lt;1%) of 'Taxon' (0 new NA)\n\n\n6.8.2 Use taxon dictionary\nAn alternative to using case_when() to fix the problem, would be to create a dictionary with bad and good species names.\nLet’s make a taxon dictionary.\n\ndictionary &lt;- tibble(bad_name = c(\"oxiria digyna\", \n                                  \"oxyria digina\", \n                                  \"oxyra digyna\", \n                                  \"calalmagrostis neglecta\"),\n                     good_name = c(\"oxyria digyna\", \n                                   \"oxyria digyna\", \n                                   \"oxyria digyna\", \n                                   \"calamagrostis neglecta\"))\n\nNext, we need to join the dictionary to the dataset using the bad name column. And with coalesce with can replace the bad names with the good names.\n\nraw_traits &lt;- raw_traits |&gt; \n  left_join(dictionary, by = c(\"Taxon\" = \"bad_name\")) |&gt; \n  mutate(Taxon = coalesce(good_name, Taxon))\n  \n\n\n6.8.3 Checking Taxon using TNRS\nIt is always advisable to check the taxonomy using a database such as TNRS, a Taxonomic Name Resolution Service.\nMaitner please add an example using TNRS."
  },
  {
    "objectID": "9_data_curation.html#visualise-data",
    "href": "9_data_curation.html#visualise-data",
    "title": "6  Data curation",
    "section": "\n6.9 Visualise data",
    "text": "6.9 Visualise data\nSome errors and problems in the data are difficult to detect by looking at the dataset. For example checking if the measurements are realistic is nearly impossible by going through a table with numbers. For this, visualising the data is much more effective.\n\n6.9.1 Histogram or density plot\nUsing histograms or density plots shows you the range of values in a variable. We are showing the density for each trait and colour the two different gradients.\n\nraw_traits |&gt; \n  ggplot(aes(x = Value, fill = Gradient)) +\n  geom_density(alpha = 0.7) +\n  scale_fill_manual(values = c(\"green4\", \"grey\")) +\n  facet_wrap(~ Trait, scales = \"free\")\n\n\n\nFigure 6.2: Density distributions of all measured traits.\n\n\n\nNote that the size traits (plant height, leaf mass, area and thickness) have distributions with very long tails. This is common for size related variables and log transformation is common for such variables.\nAlso not that leaf area has a huge tail and goes up to almost 20’000 cm2. This is a leaf of almost 2 m2, which is impossible for a plant from Svalbard. This value needs to be checked, it could be a typo.\nLet’s log transform the size traits first.\n\n\nraw_traits &lt;- raw_traits |&gt; \n  mutate(Value_log = if_else(Trait %in% c(\n    \"Plant_Height_cm\",\n    \"Wet_Mass_g\",\n    \"Dry_Mass_g\",\n    \"Leaf_Area_cm2\",\n    \"Leaf_Thickness_mm\"), log(Value), Value),\n    Trait = recode(Trait,\n                   \"Plant_Height_cm\" = \"Plant_Height_cm_log\",\n                   \"Wet_Mass_g\" = \"Wet_Mass_g_log\",\n                   \"Dry_Mass_g\" = \"Dry_Mass_g_log\",\n                   \"Leaf_Area_cm2\" = \"Leaf_Area_cm2_log\",\n                   \"Leaf_Thickness_mm\" = \"Thickness_mm_log\"))\n#&gt; Warning: There was 1 warning in `.fun()`.\n#&gt; ℹ In argument: `Value_log = if_else(...)`.\n#&gt; Caused by warning in `log()`:\n#&gt; ! NaNs produced\n#&gt; mutate: changed 5,214 values (51%) of 'Trait' (0 new NA)\n#&gt;         new variable 'Value_log' (double) with 7,987 unique values and 0% NA\n\nAnd remake the density plot using the log-transformed values.\n\nraw_traits |&gt; \n  ggplot(aes(x = Value_log, fill = Gradient)) +\n  geom_density(alpha = 0.7) +\n  scale_fill_manual(values = c(\"green4\", \"grey\")) +\n  facet_wrap(~ Trait, scales = \"free\")\n\n\n\nFigure 6.3: Density distributions of all measured traits.\n\n\n\nThe size traits do not have a long tail anymore.\nLet’s find the giant leaf. For this we can filter observations in the trait Leaf Area that have Value larger than 10.\n\nraw_traits |&gt; \n  filter(Trait == \"Leaf_Area_cm2_log\",\n         Value &gt; 10)\n#&gt; filter: removed 10,293 rows (&gt;99%), one row remaining\n#&gt; # A tibble: 1 × 11\n#&gt;   Date       Gradient  Site PlotID Individual_nr ID      Taxon       Trait Value\n#&gt;   &lt;date&gt;     &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 2018-07-18 C            5 C                  2 ANH3472 oxyria dig… Leaf… 17965\n#&gt; # ℹ 2 more variables: Elevation_m &lt;dbl&gt;, Value_log &lt;dbl&gt;\n\nThis value for Leaf Area is impossible. We can again check the envelope of this leaf to find out if this was a typo. It turns out the comma was missed when typing in the data. Let’s fix the problem with a mutate and if_else() statement. Note that we have to fix the problem for the Value and Value_log column.\n\nraw_traits &lt;- raw_traits |&gt; \n  mutate(Value = if_else(ID == \"ANH3472\" & Trait == \"Leaf_Area_cm2_log\", 1.7965, Value),\n         Value_log = if_else(ID == \"ANH3472\" & Trait == \"Leaf_Area_cm2_log\", log(1.7965), Value_log))\n#&gt; mutate: changed one value (&lt;1%) of 'Value' (0 new NA)\n#&gt;         changed one value (&lt;1%) of 'Value_log' (0 new NA)\n\n\n6.9.2 Correlations\nAnother way to check the data is to plot variables against each other that should be correlated. In this dataset, we can plot dry mass against leaf area. We would expect a positive correlation between the two variables, where large leaves have a higher dry mass.\n\nraw_traits |&gt;\n  dplyr::select(-Value) |&gt; \n  tidyr::pivot_wider(names_from = Trait, values_from = Value_log) |&gt;\n  ggplot(aes(x = Dry_Mass_g_log, y = Leaf_Area_cm2_log)) +\n  geom_point()\n#&gt; Warning: Removed 39 rows containing missing values (`geom_point()`).\n\n\n\nFigure 6.4: Correlation between leaf area and dry mass.\n\n\n\nWe see a good correlation between leaf area and dry mass. However, there is a cloud with observations that separate from the main data cloud. These leaves have a lower dry mass and area.\n\n\n\n\n\n\nExercise 3\n\n\n\nWhat could the problem be?\nHint\n\nUse filter() to look at the observations that have a higher leaf area and mass and compare them to the rest of the data.\nUnits\n\n\n\nThe problem with the separate data points is the unit. They were measured in mg instead of g and are 3 digits off. This can easily be seen, when adding the regression lines for each data cloud, and two lines in between with the same slope but the intercept being 10 times smaller.\n\n#&gt; Warning: Removed 39 rows containing missing values (`geom_point()`).\n\n\n\nFigure 6.5: Correlation between leaf area and dry mass."
  },
  {
    "objectID": "10_community.html#the-data",
    "href": "10_community.html#the-data",
    "title": "\n7  Plant community composition data\n",
    "section": "\n7.1 The data",
    "text": "7.1 The data\nWe will use the data from PFTC3 and 5 from Peru.\nTo download the data use this code:\n\nlibrary(dataDownloader)\n\nget_file(node = \"gs8u6\",\n         file = \"PFTC3-Puna-PFTC5_Peru_2018-2020_CommunityCover_clean.csv\",\n         path = \"clean_data\",\n         remote_path = \"community\")\n\nThis dataset contains percentage cover for 143 species along an elevational gradients in Peru. Three different treatments related to fire history: control (C) and burnt (B) plots. For more information about the sites and measurements see here.\nTo read in the data use the code below. Note that we remove the treatments BB and NB to simplify.\n\ncomm &lt;- read_csv(\"data/PFTC3-Puna-PFTC5_Peru_2018-2020_CommunityCover_clean.csv\") |&gt; \n  dplyr::filter(!treatment %in% c(\"BB\", \"NB\"))\n#&gt; Rows: 3665 Columns: 15\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (8): season, month, site, treatment, family, functional_group, taxon, co...\n#&gt; dbl (7): year, plot_id, cover, burn_year, elevation, latitude, longitude\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "10_community.html#diversity-indices",
    "href": "10_community.html#diversity-indices",
    "title": "\n7  Plant community composition data\n",
    "section": "\n7.2 Diversity indices",
    "text": "7.2 Diversity indices\nOne way to quantify biodiversity in a community is to calculate diversity indices. Some common indices are species richness, diversity and evenness. Species richness is the number of species in a dataset. Species diversity (there are many different indices) is a measure of species richness including the abundance of species. And evenness is quantifying how equal in terms of numbers communities are.\nTo calculate these indices we are using the vegan package. First we group the data by year, month, site, treatment and plot and calculate the indices for each plot.\n\n## Calculate responses\ndiversity_index &lt;- comm  |&gt; \n  dplyr::group_by(year, month, site, elevation, treatment, plot_id)  |&gt; \n  dplyr::summarise(richness = n(),\n            diversity = diversity(cover),\n            evenness = diversity/log(richness)) |&gt; \n    mutate(treatment = factor(treatment, levels = c(\"C\", \"B\"))) \n#&gt; `summarise()` has grouped output by 'year', 'month', 'site', 'elevation',\n#&gt; 'treatment'. You can override using the `.groups` argument.\n\nWe can now test if these diversity indices are different between the sites along the elevational gradient and the treatments. We will use a simple linear regression with diversity index as response and the interaction of elevation and treatment as predictor. Let’s start with species richness:\n\nfit &lt;- lm(richness ~ elevation * treatment, data = diversity_index)\nsummary(fit)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = richness ~ elevation * treatment, data = diversity_index)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.1286 -2.5898 -0.3141  2.5418  9.4154 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)  \n#&gt; (Intercept)            6.392339   4.908354   1.302   0.1946  \n#&gt; elevation              0.003209   0.001373   2.337   0.0206 *\n#&gt; treatmentB           -15.809315   7.121648  -2.220   0.0278 *\n#&gt; elevation:treatmentB   0.004804   0.002004   2.397   0.0177 *\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.933 on 166 degrees of freedom\n#&gt; Multiple R-squared:  0.1871, Adjusted R-squared:  0.1724 \n#&gt; F-statistic: 12.73 on 3 and 166 DF,  p-value: 1.566e-07\n\nThe summary output of the regression model shows that there is a significant interaction of elevation and treatment. Species richness increases with elevation and is overall higher in the control treatment, however species richness increases more with elevation in the burnt treatment.\nCheck model assumptions\nImportantly, we have to to check if the model assumptions are met (e.g. normality of residuals, linear relationship, homogeneity of variance, multicollinearity). For this we will use the performance package.\n\ncheck_model(fit)\n\n\n\n\nThe check.model() function visualises nicely these assumptions and explains the pattern that is expected if the assumptions are met. The plots look good, and we can assume the assumptions are met.\n\n7.2.1 Run multiple regression models\nIf we want to do the same regression for the other indices, we might want to transform the dataset into a long table and then run multiple regressions at the same time.\n\ndiversity_index &lt;- diversity_index  |&gt; \n  tidyr::pivot_longer(cols = c(richness:evenness), names_to = \"index\", values_to = \"value\") |&gt; \n  dplyr::mutate(index = factor(index, levels = c(\"richness\", \"diversity\", \"evenness\")))\n\nWe can then test run the same test again for all indices at the same time. For this we will nest() the data by index, and use a map() function to run the model for each index.\nTo get a useful model summary, we use the tidy() function from the broom pacakge.\n\ndiversity_result &lt;- diversity_index  |&gt; \n  dplyr::group_by(index)  |&gt; \n  nest(data = -c(index))  |&gt; \n  dplyr::mutate(model = map(data, ~lm(value ~ elevation * treatment, data = .x)),\n         result = map(model, tidy))  |&gt; \n  unnest(result)\n\ndiversity_result |&gt; \n  select(index, term:p.value) |&gt; \n  kbl(digits = 2)\n\n\n\nindex\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\nrichness\n(Intercept)\n6.39\n4.91\n1.30\n0.19\n\n\nrichness\nelevation\n0.00\n0.00\n2.34\n0.02\n\n\nrichness\ntreatmentB\n-15.81\n7.12\n-2.22\n0.03\n\n\nrichness\nelevation:treatmentB\n0.00\n0.00\n2.40\n0.02\n\n\ndiversity\n(Intercept)\n1.59\n0.50\n3.15\n0.00\n\n\ndiversity\nelevation\n0.00\n0.00\n0.61\n0.54\n\n\ndiversity\ntreatmentB\n-0.59\n0.73\n-0.80\n0.42\n\n\ndiversity\nelevation:treatmentB\n0.00\n0.00\n0.84\n0.40\n\n\nevenness\n(Intercept)\n0.70\n0.16\n4.54\n0.00\n\n\nevenness\nelevation\n0.00\n0.00\n-0.27\n0.78\n\n\nevenness\ntreatmentB\n-0.06\n0.22\n-0.25\n0.81\n\n\nevenness\nelevation:treatmentB\n0.00\n0.00\n0.23\n0.82\n\n\n\n\n\nThere is no difference in species diversity and evenness with elevation or the treatments.\nWe can plot the diversity indices across elevation.\n\ndiversity_index  |&gt; \n  ggplot(aes(x = elevation, y = value, colour = treatment, fill = treatment)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", formula = \"y ~ x\", alpha = 0.2) +\n  scale_colour_manual(name = \"Treatment\", \n                      labels = c(\"Control\", \"Burn\"), \n                      values = puna_treatment_colour$colour[1:3]) +\n  scale_fill_manual(name = \"Treatment\", \n                    values = puna_treatment_colour$colour[1:3]) +\n  labs(x = \"Elevation m a.s.l\", y = \"\") +\n  guides(linetype = \"none\",\n         fill = \"none\",\n         colour = guide_legend(override.aes = list(fill = NA))) +\n  facet_wrap( ~ index, scales = \"free_y\") +\n  theme_bw()\n\n\n\n\nSpecies richness increases with elevation, and more so in the burnt plots. However, there is no change in species diversity or evenness with elevation or treatment."
  },
  {
    "objectID": "10_community.html#multivariate-analysis---nmds-ordination",
    "href": "10_community.html#multivariate-analysis---nmds-ordination",
    "title": "\n7  Plant community composition data\n",
    "section": "\n7.3 Multivariate analysis - NMDS ordination",
    "text": "7.3 Multivariate analysis - NMDS ordination\nIn addition to univariate descriptor of communities such as diversity indices, we might be interested in the species composition along the elevational gradient.\nA common method is non-metric multidimensional scaling (NMDS). A NMDS collapses information from multiple dimensions to a few dimensions. This allows to visualise the data more easily.\nAn NMDS can be done using the metaMDS() function form the vegan package. First, we make the dataframe wide using pivot_wider() and use the argument values_fill = 0, because there cannot be NAs in the data. For the NMDS we will only need the species table, but not other variables like year, site etc. so we only select the species.\nThen we run the NMDS.\n\ncover_fat &lt;- comm  |&gt; \n  dplyr::select(-family, -functional_group, -c(burn_year:course))  |&gt; \n  tidyr::pivot_wider(names_from = \"taxon\", values_from = \"cover\", values_fill = 0)\n\ncover_fat_spp &lt;- cover_fat  |&gt;\n  dplyr::select(-(year:plot_id))\n\nset.seed(32)\nNMDS &lt;- metaMDS(cover_fat_spp,\n                noshare = TRUE,\n                try = 30,\n                trace = 0)\n\nfNMDS &lt;- fortify(NMDS)  |&gt; \n  dplyr::filter(score == \"sites\")  |&gt; \n  dplyr::bind_cols(cover_fat  |&gt;  \n              dplyr::select(year:plot_id))\n\nWhen doing an NMDS one has to choose the number of dimensions to show. This can be done by running the NMDS with different dimensions and then plotting this against the stress. A stress values around 0.1 are considered good.\nIn this case the stress with 2 dimensions is still a bit high, but on the other hand showing 3 dimensions of an NMDS is usually not very useful.\n\nstress &lt;- map(.x = 1:5, ~metaMDS(cover_fat_spp, k = .x)) |&gt; \n  map_dbl(\"stress\")\n\ntibble(\n    stress = stress,\n    dimensions = c(1:5))  |&gt; \n    ggplot(aes(x = dimensions, y = stress)) +\n    geom_point()\n\nVisualise\nThe output of an ordination can be visualised.\n\n\nfortify(fNMDS)  |&gt; \n  mutate(treatment = factor(treatment, levels = c(\"C\", \"B\")),\n         site = factor(site, levels = c(\"WAY\", \"ACJ\", \"PIL\", \"TRE\", \"QUE\", \"OCC\")),\n         season = if_else(season == \"dry_season\",\n                          \"Dry season\",\n                          \"Wet season\"))  |&gt; \n  ggplot(aes(x = NMDS1, y = NMDS2, colour = site, shape = treatment)) +\n  geom_point() +\n  scale_colour_manual(\"Site\", values = puna_site_colour$colour) +\n  scale_shape_manual(\"Treatment\", values=c(16, 5)) +\n  coord_equal() +\n  facet_wrap(~ season)\n\n\n\n\nThe NMDS shows that the species plant composition differs among the sites, meaning that there is species turnover along the elevaitonal gradient. However, there seems not to be much difference between the treatments or the season."
  },
  {
    "objectID": "12_traits.html#the-data-and-import",
    "href": "12_traits.html#the-data-and-import",
    "title": "\n8  Plant functional trait data\n",
    "section": "\n8.1 The data and import",
    "text": "8.1 The data and import\nWe will use the data from PFTC4 from Svalbard. For more information about the data see Chapter 6 for more information.\nWe will need to import the trait and community data.\n\ncommunity &lt;- read_csv(\"data/PFTC4_Svalbard_2018_Community_Gradient.csv\")\nraw_traits &lt;- read_csv(\"data/PFTC4_Svalbard_2018_Gradient_Traits.csv\")\n\n\n#&gt; Rows: 698 Columns: 12\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (4): Gradient, PlotID, Taxon, Weather\n#&gt; dbl  (7): Year, Site, Cover, Fertile, Elevation_m, Longitude_E, Latitude_N\n#&gt; date (1): Date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n#&gt; Rows: 11345 Columns: 15\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (7): Project, Gradient, PlotID, ID, Functional_group, Taxon, Trait\n#&gt; dbl  (7): Year, Site, Individual_nr, Value, Elevation_m, Latitude_N, Longitu...\n#&gt; date (1): Date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThe dataset has 11345 rows and 15 columns and a number of numeric, character and date variables. It contains measurements of 14 traits from two elevational gradients on Svalbard. The traits were measured on individual plants from 21 different graminoid and forb species. For more information about the sites, traits and measurements see here."
  },
  {
    "objectID": "12_traits.html#prepare-data",
    "href": "12_traits.html#prepare-data",
    "title": "\n8  Plant functional trait data\n",
    "section": "\n8.2 Prepare data",
    "text": "8.2 Prepare data\nFor the trait data we need to do some preparation. We want to log transform all the size traits and rename them. And we want to order the traits, for later when visualising. Note that some traits where removed.\n\ntraits &lt;- raw_traits |&gt; \n  mutate(Value_log = if_else(Trait %in% c(\n    \"Plant_Height_cm\",\n    \"Leaf_Thickness_mm\"), log(Value), Value),\n    Trait = recode(Trait,\n                   \"Plant_Height_cm\" = \"Plant_Height_cm_log\",\n                   \"Leaf_Thickness_mm\" = \"Thickness_mm_log\")) |&gt; \n      # order traits\n      mutate(Trait = factor(Trait, levels = c(\"Plant_Height_cm_log\", \"Thickness_mm_log\", \"LDMC\", \"SLA_cm2_g\", \"C_percent\", \"N_percent\")))"
  },
  {
    "objectID": "12_traits.html#bootstrapping",
    "href": "12_traits.html#bootstrapping",
    "title": "\n8  Plant functional trait data\n",
    "section": "\n8.3 Bootstrapping",
    "text": "8.3 Bootstrapping\nThen we do the bootstrapping, see ?sec-bootstrap for details.\n\ntrait_imp &lt;- trait_fill(comm = community,\n                            traits = traits,\n                            scale_hierarchy = c(\"Gradient\", \"Site\", \"Elevation_m\", \"PlotID\"),\n                            global = F,\n                            taxon_col = \"Taxon\",\n                            trait_col = \"Trait\",\n                            value_col = \"Value\",\n                            abundance_col = \"Cover\",\n                            min_n_in_sample = 2)\n\nCWM &lt;- trait_np_bootstrap(trait_imp, nrep = 100, sample_size = 200)\n\nCWM_moments &lt;- trait_summarise_boot_moments(CWM)\nCWM_moments\n#&gt; # A tibble: 486 × 18\n#&gt; # Groups:   Gradient, Site, Elevation_m, PlotID [81]\n#&gt;    Gradient  Site Elevation_m PlotID Trait                 n    mean ci_low_mean\n#&gt;    &lt;chr&gt;    &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;fct&gt;             &lt;int&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1 B            1        11.1 F      Plant_Height_cm_…   100   3.86        3.65 \n#&gt;  2 B            1        11.1 F      Thickness_mm_log    100   0.244       0.240\n#&gt;  3 B            1        11.1 F      LDMC                100   0.309       0.304\n#&gt;  4 B            1        11.1 F      SLA_cm2_g           100 146.        143.   \n#&gt;  5 B            1        11.1 F      C_percent           100  44.3        44.1  \n#&gt;  6 B            1        11.1 F      N_percent           100   3.22        3.18 \n#&gt;  7 B            1        11.1 B      Plant_Height_cm_…   100   3.73        3.55 \n#&gt;  8 B            1        11.1 B      Thickness_mm_log    100   0.243       0.240\n#&gt;  9 B            1        11.1 B      LDMC                100   0.285       0.282\n#&gt; 10 B            1        11.1 B      SLA_cm2_g           100 175.        174.   \n#&gt; # ℹ 476 more rows\n#&gt; # ℹ 10 more variables: ci_high_mean &lt;dbl&gt;, var &lt;dbl&gt;, ci_low_var &lt;dbl&gt;,\n#&gt; #   ci_high_var &lt;dbl&gt;, skew &lt;dbl&gt;, ci_low_skew &lt;dbl&gt;, ci_high_skew &lt;dbl&gt;,\n#&gt; #   kurt &lt;dbl&gt;, ci_low_kurt &lt;dbl&gt;, ci_high_kurt &lt;dbl&gt;"
  },
  {
    "objectID": "12_traits.html#trait-values-along-elevation",
    "href": "12_traits.html#trait-values-along-elevation",
    "title": "\n8  Plant functional trait data\n",
    "section": "\n8.4 Trait values along elevation",
    "text": "8.4 Trait values along elevation\nLet’s plot the boostraped mean trait values for each gradient (nutrient and control).\n\n\nCWM_moments |&gt; \n  ggplot(aes(x = Elevation_m, y = mean, colour = Gradient, fill = Gradient)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_colour_manual(values = c(\"green4\", \"grey\"),\n                      labels = c(\"Nutrients\", \"Control\")) +\n    scale_fill_manual(values = c(\"green4\", \"grey\"),\n                      labels = c(\"Nutrients\", \"Control\")) +\n  facet_wrap(~ Trait, scales = \"free\") +\n  theme_bw()\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nThere are some differences in traits along the two gradients, with taller, thicker leaves and higher N values at the bird cliff gradient (nutrient input by sea birds).\nLet’s test if this is the case.\n\ntrait_result &lt;- CWM_moments  |&gt; \n  dplyr::mutate(Gradient = factor(Gradient, levels = c(\"C\", \"B\"))) |&gt; \n  dplyr::group_by(Trait)  |&gt; \n  nest(data = -c(Trait))  |&gt; \n  dplyr::mutate(model = map(data, ~lm(mean ~ Elevation_m * Gradient, data = .x)),\n         result = map(model, tidy))  |&gt; \n  unnest(result)\n\ntrait_result |&gt; \n  select(Trait, term:p.value) |&gt; \n  kbl(digits = 2)\n\n\n\nTrait\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\nPlant_Height_cm_log\n(Intercept)\n2.71\n0.48\n5.69\n0.00\n\n\nPlant_Height_cm_log\nElevation_m\n0.00\n0.00\n1.29\n0.20\n\n\nPlant_Height_cm_log\nGradientB\n-1.03\n0.74\n-1.40\n0.17\n\n\nPlant_Height_cm_log\nElevation_m:GradientB\n0.02\n0.01\n2.77\n0.01\n\n\nThickness_mm_log\n(Intercept)\n0.23\n0.01\n17.82\n0.00\n\n\nThickness_mm_log\nElevation_m\n0.00\n0.00\n1.31\n0.19\n\n\nThickness_mm_log\nGradientB\n-0.04\n0.02\n-1.89\n0.06\n\n\nThickness_mm_log\nElevation_m:GradientB\n0.00\n0.00\n3.06\n0.00\n\n\nLDMC\n(Intercept)\n0.32\n0.01\n24.79\n0.00\n\n\nLDMC\nElevation_m\n0.00\n0.00\n-3.70\n0.00\n\n\nLDMC\nGradientB\n0.00\n0.02\n0.20\n0.84\n\n\nLDMC\nElevation_m:GradientB\n0.00\n0.00\n-2.44\n0.02\n\n\nSLA_cm2_g\n(Intercept)\n149.52\n6.12\n24.43\n0.00\n\n\nSLA_cm2_g\nElevation_m\n0.15\n0.04\n3.69\n0.00\n\n\nSLA_cm2_g\nGradientB\n0.65\n9.45\n0.07\n0.95\n\n\nSLA_cm2_g\nElevation_m:GradientB\n0.28\n0.08\n3.38\n0.00\n\n\nC_percent\n(Intercept)\n46.59\n0.52\n90.08\n0.00\n\n\nC_percent\nElevation_m\n-0.01\n0.00\n-3.06\n0.00\n\n\nC_percent\nGradientB\n-1.32\n0.80\n-1.65\n0.10\n\n\nC_percent\nElevation_m:GradientB\n0.00\n0.01\n0.52\n0.60\n\n\nN_percent\n(Intercept)\n2.58\n0.09\n28.24\n0.00\n\n\nN_percent\nElevation_m\n0.00\n0.00\n-0.54\n0.59\n\n\nN_percent\nGradientB\n0.28\n0.14\n1.98\n0.05\n\n\nN_percent\nElevation_m:GradientB\n0.00\n0.00\n0.33\n0.74\n\n\n\n\n\nPlant height and leaf thickness increase with elevation, but only in the bird cliff. LDMC decreases with elevation, but more along the bird cliff gradient. SLA increases with elevation and also more along the bird cliff. Leaf carbon decreases with elevation but does not differ between the gradients. And finally, leaf nitrogen does not change with elevation, but is higher at the bird cliff."
  },
  {
    "objectID": "12_traits.html#trait-ordination-pca",
    "href": "12_traits.html#trait-ordination-pca",
    "title": "\n8  Plant functional trait data\n",
    "section": "\n8.5 Trait ordination (PCA)",
    "text": "8.5 Trait ordination (PCA)\nWe can also look at the traits in a multivariate space, for example by doing a principle component analysis (PCA).\n\n\n# make wide trait table\n  cwm_fat &lt;- CWM_moments %&gt;%\n    group_by(Site) %&gt;%\n    mutate(Mean_elevation = mean(Elevation_m),\n           GS = paste0(Gradient, Site)) %&gt;%\n    select(Gradient:mean, Mean_elevation, GS) %&gt;%\n    pivot_wider(names_from = \"Trait\", values_from = \"mean\") %&gt;%\n    ungroup()\n\n  pca_output &lt;- cwm_fat %&gt;%\n    select(-(Gradient:GS)) %&gt;%\n    rda(scale = TRUE)\n\n  pca_sites &lt;- bind_cols(\n    cwm_fat %&gt;%\n      select(Gradient:GS),\n    fortify(pca_output, display = \"sites\")\n  )\n\n  pca_traits &lt;- fortify(pca_output, display = \"species\") %&gt;%\n    mutate(Trait = label)\n    \n\n\n\n# get eigenvalues\ne_B &lt;- eigenvals(pca_output)/sum(eigenvals(pca_output))\n\npca_sites |&gt; \n  ggplot(aes(x = PC1, y = PC2, \n             colour = Mean_elevation, linetype = Gradient, shape = Gradient, group = GS)) +\n    geom_point(size = 2) +\n    geom_segment(data = pca_traits,\n               aes(x = 0, y = 0, xend = PC1, yend = PC2),\n               arrow = arrow(length = unit(0.2, \"cm\")),\n               colour = \"grey50\",\n               inherit.aes = FALSE) +\n    geom_text(data = pca_traits,\n              aes(x = PC1 * 1.1,y = PC2 * 1.1, label = Trait),\n              size = 2.5,\n              inherit.aes = FALSE, colour = \"black\") +\n    coord_equal() +\n    stat_ellipse(aes(colour = Mean_elevation)) +\n    scale_colour_viridis_c(end = 0.8, option = \"inferno\", direction = -1, name = \"Elevation m a.s.l.\") +\n  scale_shape_manual(values = c(16, 1)) +\n    labs(x = glue(\"PCA1 ({round(e_B[1] * 100, 1)}%)\"),\n         y = glue(\"PCA1 ({round(e_B[2] * 100, 1)}%)\")) +\n  facet_grid(~ Gradient) +\n    theme_bw()\n\n\n\nFunctional community composition for vascular plants based on PCA-analysis for the bird cliff with nutrient input and control. Traits loadings were plotted as vectors (arrows). Trait vectors moving in a similar plane indicate trait correlations (same direction) and trade-offs (opposite direction), while perpendicular vectors indicate that traits are uncorrelated."
  }
]