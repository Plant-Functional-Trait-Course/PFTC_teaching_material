[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PFTC Teaching Material",
    "section": "",
    "text": "This book provides the teaching material for the Plant Functional Trait Courses (PFTC).\nThe PFTC courses are an international course with hands-on training in trait-based ecology. For more information about the courses see our course webpage.\nHere we provide teaching material for data collection, curation, analysis, documentation, storage, and reuse. In addition, we show reproducible and transparent workflows to make research more open and available. We cover these topics within the fields of plant functional trait ecology, ecosystem ecology, plant physiology and remote sensing.\n\n\n\n\nFigure 1: Trait data collection during PFTC4 on Svalbard."
  },
  {
    "objectID": "1_courses.html",
    "href": "1_courses.html",
    "title": "1  PFTC Course information",
    "section": "",
    "text": "The PFTC6 course will run from 23. July - 5. August 2022 and will be held in Aurland, western Norway. The location is near Bergen where the course team will be assembling before traveling to Aurland. Transport from Bergen to Aurland (by bus or car) can be organized by the course leaders. If you arrive via Oslo or elsewhere, transport to Aurland (by train or bus) needs to be organized by yourself. All flights to Bergen should be scheduled to arrive at the latest on 22nd of July and depart at the earliest on 6th of August from Bergen (other travel needs to arrive in Aurland on the 23rd at the latest, and depart on the 5th at the latest)."
  },
  {
    "objectID": "1_courses.html#previouse-courses",
    "href": "1_courses.html#previouse-courses",
    "title": "1  PFTC Course information",
    "section": "1.2 Previouse courses",
    "text": "1.2 Previouse courses\nPreviously, we have held courses in China (PFTC1 and 2), Peru (PFTC3 and 5) as well as on Svalbard (PFTC4)."
  },
  {
    "objectID": "2_study_system.html",
    "href": "2_study_system.html",
    "title": "\n2  Alpine ecosystems\n",
    "section": "",
    "text": "The PFTC courses study trait-based approaches in alpine grassland ecosystems around the world. We have chosen this ecosystem because they are impacted more strongly by climate change which cause important issues of great societal consequence, and because we have research backgrounds in this general field and system. By focusing on the same ecosystem in all courses, enables comparative approaches by combining data from the different PFTC courses. And also, everyone knows grasses are the coolest plants."
  },
  {
    "objectID": "2_study_system.html#alpine-ecosystems-in-western-norway-pftc6",
    "href": "2_study_system.html#alpine-ecosystems-in-western-norway-pftc6",
    "title": "\n2  Alpine ecosystems\n",
    "section": "\n2.1 Alpine ecosystems in Western Norway (PFTC6)",
    "text": "2.1 Alpine ecosystems in Western Norway (PFTC6)\nThe PFTC6 will be held in Aurland in the fjords of Western Norway (see Figure 2.1). We will be working on an elevational gradient that ranges between 500 and 1300 m a.s.l.\n\n\n\n\nFigure 2.1: Map of the study area and sites in Aurland, Norway.\n\n\n\n\n\n\n\n\nFigure 2.2: The fjords in Aurland in Western Norway.\n\n\n\n\nThe dominant vegetation types in this area are grasslands, pine and birch forests with bilberry understory, and heathland. The main land use in this area is grazing by sheep and goats.\nDuring the course, we will mainly focus on grassland ecosystems (see Figure 4.3 (a) and Figure 4.3 (b)).\n\n\n\n\n\n(a) Alpine grassland\n\n\n\n\n\n\n(b) Lowland pasture\n\n\n\n\nFigure 2.3: A typical alpine grasslands and one at lower elevation."
  },
  {
    "objectID": "3_three_d.html",
    "href": "3_three_d.html",
    "title": "\n3  Three-D project\n",
    "section": "",
    "text": "The aim of the ThreeD project is to study global change impacts on biodiversity and ecosystem carbon fluxes. For a complete description of the experiment see here."
  },
  {
    "objectID": "3_three_d.html#study-sites",
    "href": "3_three_d.html#study-sites",
    "title": "\n3  Three-D project\n",
    "section": "\n3.1 Study sites",
    "text": "3.1 Study sites\nThe study is conducted in three semi-natural grassland sites in western Norway. The sites are location on calcareous soil (loamy sand). The sites were chosen to fit within an elevational gradient with three temperature levels that differ in c. 400 m elevation, a temperature difference of approximately 3°C in summer temperature (Figure 3.1). The sites correspond to boreal, sub-alpine and alpine biogeographic zones. Other factors such as history, bedrock, vegetation type and structure, slope and exposure were kept as constant as possible among the selected sites within each country. The sites are grazed by sheep and goats.\n\n\n\n\nFigure 3.1: A) The experiment are set up along an elevational gradient that represents a productivity gradient. The experimental treatments are warming (brown), a grdient of nitrogen addition (grey to green) and their combination. These treatments are crossed with four grazing treatment: control (no clipping), intermediate and intensive clipping, and natural grazing outside the grazing exclosure. B) Example of a plot divided into non destructive (inner square) and and destructive sampling area (outer square).\n\n\n\n\nThe lowest site Vikesland is locate at 469 m a.s.l. (60.9°N, 7.2°E; Figure 3.2). It is located near a farm, with 200 goats. In summer, these goats are moving up and down the mountains each day, to graze at higher elevation and being milked at the farm in the valley. The vegetation is dominated by Agrostis capillaris, Anthoxantum odoratum, Achillea millefolium, Ranunculus acris, and Rumex acetosa.\n\n\n\n\nFigure 3.2: The lowest site at the farm Vikesland.\n\n\n\n\nThe middle site Joasete is a summer farm and located at 920 m a.s.l (Figure 3.3). The area around the summer farm is mostly grazed by sheep and sometimes goats. The vegetation at Joasete is well adapted to the grazing pressure and nutrient input by the animals. The dominant plant species are Agrostis capillaris, Deschampsia cespitosa, Achillea millefolium, Ranunculus acris, Ranunculus repens, and Rumex acetosa.\n\n\n\n\nFigure 3.3: The middle site at the summer farm Joasete.\n\n\n\n\nThe highest site Liahovden is located at 1290 m a.s.l (Figure 3.4). It is grazing moderately by sheep, deer and reindeer. The vegetation is a species rich grassland, typical for nutrient soils in Norwegian alpine vegetation with Achillea millefolium, Antennaria dioica, Bistorta vivipara, Leontodon autumnalis, Silene acaulis, and Thalictrum alpinum.\n\n\n\n\nFigure 3.4: The higsest site at Liahovden."
  },
  {
    "objectID": "3_three_d.html#experimental-treatments",
    "href": "3_three_d.html#experimental-treatments",
    "title": "\n3  Three-D project\n",
    "section": "\n3.2 Experimental treatments",
    "text": "3.2 Experimental treatments\nAt each site, ten blocks, with 8 plots (50 x 50 cm) were marked in each corner. Six plots were chosen relatively close to each other (inside the fence) and two plots were chosen further away (outside fence). Each plot was given a unique originPlotID starting at the upper left corner in block 1 and the highest site. The numbering was continued to 160. After transplanting, each turf also received a unique destinationPlotID (a number from 1-200; see Figure 3.1 and below). Each plot received a combination of each treatment randomly (warming, nitrogen addition and grazing, see below). The randomization of the treatments was done in two steps. First, the 10 nitrogen levels were assigned randomly per block (i.e. block 1 received the same nitrogen level in each site). We chose to randomize the nitrogen treatment at the block level to avoid nitrogen contamination between the plots within the blocks. Second, the warming and grazing treatments were randomized within block. The six plots within each block (inside the fence) were randomly assigned a warming and grazing treatment. The two plots per block located outside the fence, were randomly assigned a warming treatment.\n\n3.2.1 Warming treatment\nThe warming treatment was conducted at the end of the growing season in 2019, by transplanting entire plant communities to lower elevation (c. +3°C; Figure 3.1). The upslope left-hand corner of each turf was marked with a toothpick that the turfs could be placed in the similar position relative to the slope and block orientation at the destination site. We used a knife to cut the turfs to 50 x 50 cm and to a depth of c. 10 - 25 cm (Figure 3.5), unless the soil was shallower, as was the case for some of the alpine plots. After excavation, the turfs were packed into a cardboard box and transported to their respective target sites within one day. The control plots were not excavated or moved. We did not have local transplants, to control for the transplanting effect, because this was tested in a previous project and the transplanting did not affect species composition in Norway (Vandvik et al. 2020) or China (Yang et al. 2018).\n\n\n\n\nFigure 3.5: A turf that is being transplanted.\n\n\n\n\nThe turfs were fitted into the gaps created by excavating turfs at the destination site, except for the low site, where gaps had to be made. Each block received one plot of each treatment. Turfs were placed in the block with the same numerical value (1 - 10) and nitrogen level in the destination site as they originated from in the origin site. Transplanted turfs were carefully planted into their destination plots (destinationPlotID) ensuring that the turf orientation was correct (using the toothpick marking the uphill left corner of each turf) and that the soil surface was in plane with the surrounding vegetation, and that the edges of the excavated plot was in good contact with the edges of the gap created when the original turf was excavated from the plot (Figure 3.6). If necessary, loose soil was carefully removed from the underside of the turf, or local soil was added to the gap or around the edges to achieve this.\n\n\n\n\nFigure 3.6: Turfs that have been transplanted from Liahovden to lower elevation at Joasete.\n\n\n\n\n\n3.2.2 Nitrogen addition\nIn each plot we added slow dissolving fertilizer as pellets (YaraBela OPTI-NS 27-0-0 (4S)). We used oxidised nitrogen (NO and N2O) formed mainly by combustion processes, which are the main sources of atmospheric nitrogen deposition in remote regions (i.e., away from intensive agriculture and other sources or reduced nitrogen). The fertilizer was added once at the start and once in the middle of the growing season from 2020 - 2022. Each block received one of the seven nitrogen levels: 0, 0.5, 1, 5, 10, 50, 100, 150 kg N ha−1 yr−1. Three of the blocks were controls and received 0 kg N ha−1 yr−1.\nThe natural nitrogen deposition in Norway is 1.5-3.5 kg N ha−1 yr−1. The critical load for changing species composition in these alpine grasslands is approximately 5-10 kg N ha−1 yr−1 in Norway. We therefore wanted to have a range of nitrogen levels that were below and well above this critical load.\n\n3.2.3 Grazing treatment\nThe warming and nitrogen treatments were crossed with four grazing treatments. Grazing was simulated by clipping the vegetation manually with scissors 2-3 cm above the ground (Figure 3.7). The four grazing treatments were natural grazing (N; outside the fence), medium level of grazing (M; 2x clipp), intensive level of grazing (I; 4x clipp), and untreated control plots (C). The intermediate clipping level reflects the natural grazing level outside the exclosure and should control for differences between grazing and clipping (i.e. clipping is not selective and will not add faeces and urine). The medium and intensive plots were clipped 2 or 4 times during the growing season. The clipping treatment was conducted in 2020 - 2022.\n\n\n\n\nFigure 3.7: A plot that has been clipped and the biomass sorted to functional groups."
  },
  {
    "objectID": "3_three_d.html#references",
    "href": "3_three_d.html#references",
    "title": "\n3  Three-D project\n",
    "section": "\n3.3 References",
    "text": "3.3 References\n\n\n\n\nVandvik, Vigdis, Olav Skarpaas, Kari Klanderud, Richard J Telford, Aud H Halbritter, and Deborah E Goldberg. 2020. “Biotic Rescaling Reveals Importance of Species Interactions for Variation in Biodiversity Responses to Climate Change.” Proc. Natl. Acad. Sci. U. S. A. 117 (37): 22858–65.\n\n\nYang, Yan, Aud Helen Halbritter, Kari Klanderud, Richard J Telford, Genxu Wang, and Vigdis Vandvik. 2018. “Transplants, Open Top Chambers (OTCs) and Gradient Studies Ask Different Questions in Climate Change Effects Studies.” Front. Plant Sci. 9: 1574."
  },
  {
    "objectID": "4_trait_collection.html",
    "href": "4_trait_collection.html",
    "title": "\n4  The trait wheel\n",
    "section": "",
    "text": "This protocol shows how to collect, measure, check and document leaf functional traits for vascular plants using the trait wheelTW (Figure 4.1). The protocol is based on the trait handbook from Perez-Harguindeguy et al. (2013)."
  },
  {
    "objectID": "4_trait_collection.html#references",
    "href": "4_trait_collection.html#references",
    "title": "\n4  The trait wheel\n",
    "section": "\n4.1 References",
    "text": "4.1 References\n\n\n\n\nPérez-Harguindeguy, N, S Dı́az, E Garnier, S Lavorel, H Poorter, P Jaureguiberry, M S Bret-Harte, et al. 2013. “New Handbook for Standardised Measurement of Plant Functional Traits Worldwide.” Australian Journal of Botany."
  },
  {
    "objectID": "5_pftc_data.html",
    "href": "5_pftc_data.html",
    "title": "5  Working with PFTC data",
    "section": "",
    "text": "The cleaned datasets from the PFTC courses are stored on an OSF repository (short repo). Each course has it’s own data repo. The following table shows the link to each of the repos.\n\n\nCourse\nCountry\nData repo\n\n\n\nPFTC1 and 2\nChina\nChina repo\n\n\nPFTC3 and 5\nPeru\nPeru repo\n\n\nPFTC4\nSvalbard\nSvalbard repo\n\n\nPFTC6\nNorway\n3D repo\n\n\n\n\nIncline repo"
  },
  {
    "objectID": "5_pftc_data.html#data-paper-and-data-documentation",
    "href": "5_pftc_data.html#data-paper-and-data-documentation",
    "title": "5  Working with PFTC data",
    "section": "\n5.2 Data paper and data documentation",
    "text": "5.2 Data paper and data documentation\nThe site, experiment, data collection methods and data dictionaries for each course are described in data papers. Some information can also be found on the GitHub readme file.\n\n\nCourse\nCountry\nData paper/documentation\n\n\n\nPFTC1 and 2\nChina\nData paper\n\n\nPFTC3 and 5\nPeru\nGitHub readme\n\n\nPFTC4\nSvalbard\nGitHub readme\n\n\nPFTC6\nNorway\n3D: GitHub readme\n\n\nPFTC6\nNorway\nIncline: GitHub readme\n\n\n\nRead the papers and documentation carefully before using the data."
  },
  {
    "objectID": "5_pftc_data.html#data-usage-and-citation",
    "href": "5_pftc_data.html#data-usage-and-citation",
    "title": "5  Working with PFTC data",
    "section": "\n5.3 Data usage and citation",
    "text": "5.3 Data usage and citation\nThe data are available for use and teaching purposes under a CC-BY licence. We suggest to cite the data paper if available, or alternatively the OSF repo. We appreciate being contacted for advice or collaboration, if relevant, by users of these data. In cases where our data make up >10% of the data used in a downstream publication, we suggest contacting us for our contribution and collaboration."
  },
  {
    "objectID": "5_pftc_data.html#download-pftc-data",
    "href": "5_pftc_data.html#download-pftc-data",
    "title": "5  Working with PFTC data",
    "section": "\n5.4 Download PFTC data",
    "text": "5.4 Download PFTC data\nWe have created a R package to download the data, called dataDownloader. If you are using the package for the first time you need to install the package using the command below. If you have used it before, just run the second line of code to load the package.\n\ndevtools::install_github(\"Between-the-Fjords/dataDownloader\")\nlibrary(dataDownloader)\n\nNow you can download the all the files you need. Let’s download the community data and the trait from the Svalbard course.\n\nget_file(node = \"smbqh\",\n         file = \"PFTC4_Svalbard_2018_Gradient_Traits.csv\",\n         path = \"webpage/data\",\n         remote_path = \"Traits\")\n                       \nget_file(node = \"smbqh\",\n         file = \"PFTC4_Svalbard_2018_Community_Gradient.csv\",\n         path = \"webpage/data\",\n         remote_path = \"Community\")\n\nExercise\nNow it is your turn. Copy the code into your console and download the data."
  },
  {
    "objectID": "6_biostats.html",
    "href": "6_biostats.html",
    "title": "\n6  Introduction to R, RStudio and GitHub\n",
    "section": "",
    "text": "The BioSTATS books are an extensive resource for getting started with R and RStudio, working in R, coding, using Rmarkdown, git and GitHub and creating an R package."
  },
  {
    "objectID": "7_reproducible.html",
    "href": "7_reproducible.html",
    "title": "\n7  Reproducible workflows\n",
    "section": "",
    "text": "Reproduciblitiy …"
  },
  {
    "objectID": "8_data_curation.html",
    "href": "8_data_curation.html",
    "title": "\n8  Data curation\n",
    "section": "",
    "text": "Data curation, transformation or cleaning is the first step after digitizing the data. Each dataset has to be checked for errors and corrected as best as possible. This tutorial shows how to check your dataset for errors and how to correct them.\nFor this tutorial we will be working with the trait dataset from Svalbard. See chapter Chapter 5 for how to access the data and information about the study, experiment and datasets."
  },
  {
    "objectID": "8_data_curation.html#useful-packages",
    "href": "8_data_curation.html#useful-packages",
    "title": "\n8  Data curation\n",
    "section": "\n8.1 Useful packages",
    "text": "8.1 Useful packages\nThere are a couple of R packages that are useful for this work. First, tidyverse is a collection of R packages used for basic data manipulation and analysis.\nIf you have never used the packages you need to install it first using the function install.packages(\"tidyverse\"). Otherwise, you can just load the packages.\n\n\nlibrary(tidyverse)\n\nSecond, another useful package for data curation is tidylog, which is built on the dplyr and tidyr packages and provides useful information about the functions used.\nTidylog will for example tell you how many rows have been removed and are remaining when using the filter() function or how many rows match when using a join function. The information is always indicated in absolute numbers and percentage. The additional information is very useful to check if the right observations have been removed or manipulated, because mistakes are easily done.\nLet’s install and/or load tidylog.\n\n\nlibrary(tidylog)\n\nNote, that once tidylog is loaded it will automatically prioritize the tidylog function before the dplyr and tidyr functions. You actively have to choose if you do not want to use the tidylog version by using this notation: dplyr::filter()."
  },
  {
    "objectID": "8_data_curation.html#import-data",
    "href": "8_data_curation.html#import-data",
    "title": "\n8  Data curation\n",
    "section": "\n8.2 Import data",
    "text": "8.2 Import data\nThe first step is to import the data to R. The data is stored as a csv file and we can use the function read_csv() to import that data. If your data has another format or importing data is new to, you have a look at this page.\n\n\nraw_traits <- read_csv(\"data/PFTC4_Svalbard_2018_Gradient_Traits.csv\")\n#> Rows: 11345 Columns: 15\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): Project, Gradient, PlotID, ID, Functional_group, Taxon, Trait\n#> dbl  (7): Year, Site, Individual_nr, Value, Elevation_m, Latitude_N, Longitu...\n#> date (1): Date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nGive the dataset a name that indicates that this is the raw data.\nThe dataset contains measurements of 14 traits from two elevational gradients on Svalbard. The traits were measured on individual plants from 21 different graminoid and forb species. For more information about the sites, traits and measurements see here.\nSome manipulation\nLet us introduce some errors to the dataset.\nThe code to do this is hidden. But if you want to replicate the code to introduce errors you can find the code here."
  },
  {
    "objectID": "8_data_curation.html#first-check-of-the-dataset",
    "href": "8_data_curation.html#first-check-of-the-dataset",
    "title": "\n8  Data curation\n",
    "section": "\n8.3 First check of the dataset",
    "text": "8.3 First check of the dataset\nBy typing raw_traits in the console it will display the first rows and columns of the dataset.\n\n\nraw_traits\n#> # A tibble: 11,346 × 12\n#>    Date       Gradient  Site PlotID Individual_nr ID      Taxon    Trait   Value\n#>    <chr>      <chr>    <dbl> <chr>          <dbl> <chr>   <chr>    <chr>   <dbl>\n#>  1 2018-07-20 B            5 D                  1 AIB1395 saxifra… Plan… 6.5 e+0\n#>  2 2018-07-20 B            5 D                  1 AIB1395 saxifra… Wet_… 2.92e-2\n#>  3 2018-07-20 B            5 D                  1 AIB1395 saxifra… Dry_… 4   e-3\n#>  4 2018-07-20 B            5 D                  1 AIB1395 saxifra… Leaf… 5.66e-1\n#>  5 2018-07-20 B            5 D                  1 AIB1395 saxifra… Leaf… 6.75e-1\n#>  6 2018-07-20 B            5 D                  1 AIB1395 saxifra… SLA_… 1.69e+2\n#>  7 2018-07-20 B            5 D                  1 AIB1395 saxifra… LDMC  1.37e-1\n#>  8 2018-07-20 B            5 D                  1 AIB1395 saxifra… C_pe… 3.89e+1\n#>  9 2018-07-20 B            5 D                  1 AIB1395 saxifra… N_pe… 1.14e+0\n#> 10 2018-07-20 B            5 D                  1 AIB1395 saxifra… CN_r… 3.41e+1\n#> # … with 11,336 more rows, and 3 more variables: Elevation_m <dbl>,\n#> #   Latitude_N <dbl>, Longitude_E <dbl>\n\nAt the top you can see that the dataset has 11346 observations and 12 columns. These numbers give you a first impression if you have imported the right file, and if all your observations and columns are there.\n\n8.3.1 Check the data type\nThe next thing to check is if the variables have the right data type (or class in R terminology). For each variable the output indicates the data type. The most common types are dbl (numeric or integer), chr (character), or date (date).\nIf you want to know more about data types see here.\nNow we want to check if the variables have the right data type. The first variable Date is a character, which is not correct. This probably means that one or several observations have a wrong date. Let us check all different values for the variable Date. For this we can use the function distinct() on the variable Date.\n\n\nraw_traits |> \n  distinct(Date)\n#> distinct: removed 11,338 rows (>99%), 8 rows remaining\n#> # A tibble: 8 × 1\n#>   Date      \n#>   <chr>     \n#> 1 2018-07-20\n#> 2 2018-07-18\n#> 3 2018-07-21\n#> 4 2018-07-24\n#> 5 2018-07-19\n#> 6 2018-07-17\n#> 7 18        \n#> 8 <NA>\n\nWe can see that there are 6 distinct dates in this variable. One of the dates is “18”, which is not a correct date format and turned the variable into a character. Note that the additional information from the tidylog package about the distinct() function. It shows the number of rows removed and remaining.\nThe next step is to check where the problem occurred. For this we can use the function filter() to extract all observations with the date 18. We can use as.data.frame() to display the whole table.\n\n\nraw_traits |> \n  filter(Date == \"18\") |> \n  View()\n\n\n#> filter: removed 11,339 rows (>99%), 7 rows remaining\n#> # A tibble: 7 × 12\n#>   Date  Gradient  Site PlotID Individual_nr ID      Taxon         Trait    Value\n#>   <chr> <chr>    <dbl> <chr>          <dbl> <chr>   <chr>         <chr>    <dbl>\n#> 1 18    C            1 A                  3 AMO3822 salix polaris Plant… 1.1 e+0\n#> 2 18    C            1 A                  3 AMO3822 salix polaris Wet_M… 5.76e-3\n#> 3 18    C            1 A                  3 AMO3822 salix polaris Dry_M… 2   e-3\n#> 4 18    C            1 A                  3 AMO3822 salix polaris Leaf_… 1.88e-1\n#> 5 18    C            1 A                  3 AMO3822 salix polaris Leaf_… 2.84e-1\n#> 6 18    C            1 A                  3 AMO3822 salix polaris SLA_c… 1.42e+2\n#> 7 18    C            1 A                  3 AMO3822 salix polaris LDMC   3.47e-1\n#> # … with 3 more variables: Elevation_m <dbl>, Latitude_N <dbl>,\n#> #   Longitude_E <dbl>\n\nWe see that it is a single observation (with multiple traits) that has the wrong date. The next step is to check the raw data, notes, photos, etc. to find the correct date for this observations. It is important to keep the data entry sheets, take a photo of them and keep the field notes to be able to fix such problems.\n\n#knitr::include_graphics(\"images/resource/...\")\n\n\nSince the value for date is 18, we will assume now that this was a typo and that the correct date is 2018-07-18. Let’s replace this value and give the variable the right class.\nFor this we will use the function mutate() which adds or manipulates a column. Inside the mutate we will use the case_when() function to replace the date for a specific ID. We are using the function with a single statement, however this is a powerful function that allow for multiple statements (many if else conditions). To give the variable the correct class, we use the ymd() function from the lubridate package. Note that we now have to assign the table to a new or the same name to make the change permanent.\n\n\nraw_traits <- raw_traits |> \n  mutate(Date = case_when(ID == \"AMO3822\" ~ \"2018-07-18\",\n                          TRUE ~ Date)) |> \n  mutate( Date = ymd(Date))\n#> mutate: changed 7 values (<1%) of 'Date' (0 new NA)\n#> mutate: converted 'Date' from character to Date (0 new NA)\n\nAn important step when cleaning data is to check that you have done the right thing. The tidylog functions show that for 7 observation Date has been changed. This matches with the number of observations that had a wrong date.\nTo be sure we can look at the specific leaf (ID == “AMO3822”) and see if the date is now corrected. Another way would be to run the distinct(Date) function again.\n\n\nraw_traits |> \n  filter(ID == \"AMO3822\") |> \n  select(Date)\n#> filter: removed 11,339 rows (>99%), 7 rows remaining\n#> select: dropped 11 variables (Gradient, Site, PlotID, Individual_nr, ID, …)\n#> # A tibble: 7 × 1\n#>   Date      \n#>   <date>    \n#> 1 2018-07-18\n#> 2 2018-07-18\n#> 3 2018-07-18\n#> 4 2018-07-18\n#> 5 2018-07-18\n#> 6 2018-07-18\n#> 7 2018-07-18\n\nThe date has been fixed."
  },
  {
    "objectID": "8_data_curation.html#exercise",
    "href": "8_data_curation.html#exercise",
    "title": "\n8  Data curation\n",
    "section": "Exercise",
    "text": "Exercise\nNow it is your turn. Check if the data type for the variable Date is now correct.\n\nHint\n\ntype raw_traits to look at the whole dataset where the datatype of each variable is indicated\nuse class(raw_traits$Date) which will tell you directly what type of class the variable has\nuse map(raw_traits, class) to get the class of all variable in the dataframe"
  },
  {
    "objectID": "8_data_curation.html#check-for-duplicates",
    "href": "8_data_curation.html#check-for-duplicates",
    "title": "\n8  Data curation\n",
    "section": "\n8.4 Check for duplicates",
    "text": "8.4 Check for duplicates\nAnother common problem is duplicate observations. This can happen when data is entered twice. The why to find duplicates is to check that the combination of variables are unique. In our dataset, we expect that Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon and Trait should be unique, and only occurring once.\nTo check this, we can group_by() these variables and filter() for observations that occur more than once.\n\n\nraw_traits |> \n  group_by(Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon, Trait) |> \n  filter(n() > 1)\n#> group_by: 8 grouping variables (Date, Gradient, Site, PlotID, Individual_nr, …)\n#> filter (grouped): removed 11,344 rows (>99%), 2 rows remaining\n#> # A tibble: 2 × 12\n#> # Groups:   Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon, Trait [1]\n#>   Date       Gradient  Site PlotID Individual_nr ID      Taxon     Trait   Value\n#>   <date>     <chr>    <dbl> <chr>          <dbl> <chr>   <chr>     <chr>   <dbl>\n#> 1 2018-07-20 B            3 C                  3 BEK3638 salix po… Dry_… 0.00275\n#> 2 2018-07-20 B            3 C                  3 BEK3638 salix po… Dry_… 0.00275\n#> # … with 3 more variables: Elevation_m <dbl>, Latitude_N <dbl>,\n#> #   Longitude_E <dbl>\n\nThere is one duplicate entry.\nNote that Value was not included in the group_by(). This was done intentionally, because a common mistake is to have a duplicate, but with a different value. This is either because one of the variables is wrong, e.g. it has the wrong Site and therefore appears to be a duplicate. Alternatively, the leaf could have been measured twice by accident, which would likely give two slightly different values. When getting a duplicate, these different options for why there is a duplicate have to be considered and carefully checked in the raw data.\nIn this case, we will assume that the leaf has only been measured once, but the data has been entered twice. Thus, the two entries are exact duplicates.\nTo fix the duplicate problem, we group by the variables we expect to be unique. Then we use distinct() with the argument .keep_all = TRUE to remove the duplicates.\n\n\nraw_traits2 <- raw_traits |> \n  group_by(Date, Gradient, Site, PlotID, Individual_nr, ID, Taxon, Trait) |> \n  distinct(.keep_all = TRUE)\n#> group_by: 8 grouping variables (Date, Gradient, Site, PlotID, Individual_nr, …)\n#> distinct (grouped): removed one row (<1%), 11,345 rows remaining\n\nTidylog allows us to see what happens and how many rows have been removed. There are 8 grouping variables and as expected, one row is filtered away, which is the duplicated row.\nWe can also run the code from above again to check if the duplicate is gone."
  },
  {
    "objectID": "8_data_curation.html#check-for-missing-data",
    "href": "8_data_curation.html#check-for-missing-data",
    "title": "\n8  Data curation\n",
    "section": "\n8.5 Check for missing data",
    "text": "8.5 Check for missing data\nA common problem in a dataset are missing values.\nHow to detect missing values…\nOnce the missing values are detected one has to decide if the missing data can be recovered, or if the missing values should be removed from the dataset.\n\n\nraw_traits <- raw_traits |> \n  drop_na(Value)\n#> drop_na: removed 3 rows (<1%), 11,343 rows remaining\n\nThis operation has removed 3 rows, which is the number of NA’s in the dataset.\n\n8.5.1 Check values within variables\n\n\nraw_traits |> \n  distinct(Taxon) |> \n  arrange(Taxon) |> \n  print(n = Inf)\n#> distinct: removed 11,299 rows (>99%), 44 rows remaining\n#> # A tibble: 44 × 1\n#>    Taxon                   \n#>    <chr>                   \n#>  1 alopecurus ovatus       \n#>  2 aulacomnium turgidum    \n#>  3 bistorta vivipara       \n#>  4 calamagrostis neglecta  \n#>  5 cassiope tetragona      \n#>  6 cerastium arcticum      \n#>  7 dicranum sp             \n#>  8 draba arctica           \n#>  9 draba oxycarpa          \n#> 10 dryas octopetala        \n#> 11 equisetum arvense       \n#> 12 equisetum scirpoides    \n#> 13 festuca rubra           \n#> 14 festuca viviparoidea    \n#> 15 hylocomium splendens    \n#> 16 luzula confusa          \n#> 17 luzula nivalis          \n#> 18 micranthes hieraciifolia\n#> 19 micranthes nivalis      \n#> 20 niphotrichum canescens  \n#> 21 niphotrichum sp         \n#> 22 oxiria digyna           \n#> 23 oxyra digyna            \n#> 24 oxyria digina           \n#> 25 oxyria digyna           \n#> 26 pedicularis hirsuta     \n#> 27 poa alpina              \n#> 28 poa arctica             \n#> 29 poa pratensis           \n#> 30 polytrichum piliferum   \n#> 31 polytrichum sp          \n#> 32 potentilla hyparctica   \n#> 33 ranunculus sulphureus   \n#> 34 salix polaris           \n#> 35 sanionia sp             \n#> 36 saxifraga cernua        \n#> 37 saxifraga cespitosa     \n#> 38 saxifraga hirculus      \n#> 39 saxifraga oppositifolia \n#> 40 silene acaulis          \n#> 41 stellaria longipes      \n#> 42 syntrichia ruralis      \n#> 43 tomentypnum nitens      \n#> 44 trisetum spicatum\n\n4 different versions of oxyra digyna! rename alternative would be to use a dictionary.\n\n\nraw_traits <- raw_traits |> \n  mutate(Taxon = if_else(Taxon %in% c(\"oxiria digyna\", \"oxyria digina\", \"oxyra digyna\"), \"oxyria digyna\", Taxon))\n#> mutate: changed 28 values (<1%) of 'Taxon' (0 new NA)"
  },
  {
    "objectID": "8_data_curation.html#visualise-data",
    "href": "8_data_curation.html#visualise-data",
    "title": "\n8  Data curation\n",
    "section": "\n8.6 Visualise data",
    "text": "8.6 Visualise data\nSome errors and problems in the data are difficult to detect. Checking if the measurements are realistic is nearly impossible by looking at a dataframe. For this, visualising the data is much more effective.\nMake histograms, this shows the range of the values\n\nraw_traits |> \n  ggplot(aes(x = Value, fill = Gradient)) +\n  geom_density(alpha = 0.7) +\n  scale_fill_manual(values = c(\"green4\", \"grey\")) +\n  facet_wrap(~ Trait, scales = \"free\")\n\n\n\n\nNote that the size traits (height, mass, area and thickness) have very long tails. It is common to log transform such variables to better see the full range of the variables.\nLeaf area has a huge tail and goes up to almost 20’000 cm2. This would be a leaf of almost 2 m2, which is nearly impossible. This value needs to be checked, it could be a typo.\nLet’s log transform the size traits.\n\n\nraw_traits <- raw_traits |> \n  mutate(Value = if_else(Trait %in% c(\n    \"Plant_Height_cm\",\n    \"Wet_Mass_g\",\n    \"Dry_Mass_g\",\n    \"Leaf_Area_cm2\",\n    \"Leaf_Thickness_mm\"), log(Value), Value),\n    Trait = recode(Trait,\n                   \"Plant_Height_cm\" = \"Plant_Height_cm_log\",\n                   \"Wet_Mass_g\" = \"Wet_Mass_g_log\",\n                   \"Dry_Mass_g\" = \"Dry_Mass_g_log\",\n                   \"Leaf_Area_cm2\" = \"Leaf_Area_cm2_log\",\n                   \"Leaf_Thickness_mm\" = \"Thickness_mm_log\"))\n#> Warning in log(Value): NaNs produced\n#> mutate: changed 5,428 values (48%) of 'Trait' (0 new NA)\n#>         changed 5,428 values (48%) of 'Value' (0 new NA)\n\nAnd make plot again.\n\nraw_traits |> \n  ggplot(aes(x = Value, fill = Gradient)) +\n  geom_density(alpha = 0.7) +\n  scale_fill_manual(values = c(\"green4\", \"grey\")) +\n  facet_wrap(~ Trait, scales = \"free\")\n\n\n\n\nThe size traits are now easier to read.\nAnother way to check the data is to plot correlated values against each other. In this dataset, we can plot dry mass against leaf area. We would expect a positive correlation between the two variables, where large leaves have a higher dry mass.\n\nraw_traits |> \n  pivot_wider(names_from = Trait, values_from = Value) |> \n  ggplot(aes(x = Dry_Mass_g_log, y = Leaf_Area_cm2_log)) +\n  geom_point()"
  },
  {
    "objectID": "9_community.html",
    "href": "9_community.html",
    "title": "\n9  Plant community composition data\n",
    "section": "",
    "text": "We will use the data from PFTC3 and 5 from Peru.\nDownload data\n\n\nlibrary(dataDownloader)\n\nget_file(node = \"gs8u6\",\n         file = \"PFTC3-Puna-PFTC5_Peru_2018-2020_CommunityCover_clean.csv\",\n         path = \"clean_data\",\n         remote_path = \"community\")\n\nThis dataset contains percentage cover for 143 species along an elevational gradients in Peru. Three different treatments related to fire history: control (C), burnt (B) and newly burnt (NB)). For more information about the sites and measurements see here.\nTo read in the data use the code below. Note that we remove the treatment BB which has only a few observation from one site.\n\n\ncomm <- read_csv(\"data/PFTC3-Puna-PFTC5_Peru_2018-2020_CommunityCover_clean.csv\") |> \n  filter(treatment != \"BB\")\n#> Rows: 3665 Columns: 15\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (8): season, month, site, treatment, family, functional_group, taxon, co...\n#> dbl (7): year, plot_id, cover, burn_year, elevation, latitude, longitude\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n9.0.1 Diversity indices\nOne way to quantify the number of species species is to calculate diversity indices. Some common indices are species richness, diversity and evenness.\nTo calculate these indices we are using the vegan package.\n\n\n## Calculate responses\ndiversity_index <- comm  |> \n  group_by(year, month, site, elevation, treatment, plot_id)  |> \n  summarise(richness = n(),\n            diversity = diversity(cover),\n            evenness = diversity/log(richness))  |> \n  # make long dataframe\n  pivot_longer(cols = c(richness:evenness), names_to = \"index\", values_to = \"value\") |> \n  mutate(index = factor(index, levels = c(\"richness\", \"diversity\", \"evenness\")))\n#> `summarise()` has grouped output by 'year', 'month', 'site', 'elevation',\n#> 'treatment'. You can override using the `.groups` argument.\n\nWe can now test if these diversity indices are different between the sites along the elevational gradient and the treatments. We will use a simple linear model with diversity index as response and the interaction of elevation and treatment as predictor.\n\n\ndiversity_result <- diversity_index  |> \n  filter(treatment %in% c(\"C\", \"B\", \"NB\"))  |> \n  mutate(treatment = factor(treatment, levels = c(\"C\", \"B\", \"NB\")))  |> \n  group_by(index)  |> \n  nest(data = -c(index))  |> \n  mutate(model = map(data, ~lm(value ~ elevation * treatment, data = .x)),\n         result = map(model, tidy))  |> \n  unnest(result)\n\ndiversity_result |> \n  select(index, term:p.value) |> \n  kbl(digits = 2)\n\n\n\n\n index \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n\n\n richness \n    (Intercept) \n    6.39 \n    5.11 \n    1.25 \n    0.21 \n  \n\n richness \n    elevation \n    0.00 \n    0.00 \n    2.25 \n    0.03 \n  \n\n richness \n    treatmentB \n    -15.81 \n    7.41 \n    -2.13 \n    0.03 \n  \n\n richness \n    treatmentNB \n    -105.11 \n    15.57 \n    -6.75 \n    0.00 \n  \n\n richness \n    elevation:treatmentB \n    0.00 \n    0.00 \n    2.30 \n    0.02 \n  \n\n richness \n    elevation:treatmentNB \n    0.03 \n    0.00 \n    6.44 \n    0.00 \n  \n\n diversity \n    (Intercept) \n    1.59 \n    0.49 \n    3.24 \n    0.00 \n  \n\n diversity \n    elevation \n    0.00 \n    0.00 \n    0.63 \n    0.53 \n  \n\n diversity \n    treatmentB \n    -0.59 \n    0.71 \n    -0.83 \n    0.41 \n  \n\n diversity \n    treatmentNB \n    -7.06 \n    1.49 \n    -4.72 \n    0.00 \n  \n\n diversity \n    elevation:treatmentB \n    0.00 \n    0.00 \n    0.86 \n    0.39 \n  \n\n diversity \n    elevation:treatmentNB \n    0.00 \n    0.00 \n    4.47 \n    0.00 \n  \n\n evenness \n    (Intercept) \n    0.70 \n    0.15 \n    4.80 \n    0.00 \n  \n\n evenness \n    elevation \n    0.00 \n    0.00 \n    -0.29 \n    0.77 \n  \n\n evenness \n    treatmentB \n    -0.06 \n    0.21 \n    -0.26 \n    0.79 \n  \n\n evenness \n    treatmentNB \n    -1.01 \n    0.45 \n    -2.27 \n    0.02 \n  \n\n evenness \n    elevation:treatmentB \n    0.00 \n    0.00 \n    0.24 \n    0.81 \n  \n\n evenness \n    elevation:treatmentNB \n    0.00 \n    0.00 \n    2.16 \n    0.03 \n  \n\n\n\n\nSpecies richness and diversity increase for the NB treatment, but not for the other treatments.\nCheck model assumptions\nTo check if the model assumptions are met, we will use the performance package.\n\n\nrichness <- diversity_index |> \n  filter(index == \"richness\")\n\nfit <- lm(value ~ elevation * treatment, data = richness)\n\nplot <- check_model(fit)\n\nplot\n\nDiversity change with elevation\nWe can plot the diversity indices across elevation.\n\n\ndiversity_index %>%\n  ggplot(aes(x = elevation, y = value, colour = treatment, fill = treatment)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", formula = \"y ~ x\", alpha = 0.2) +\n  scale_colour_manual(\"Treatment\", values = puna_treatment_colour$colour[1:3]) +\n  scale_fill_manual(\"Treatment\", values = puna_treatment_colour$colour[1:3]) +\n  labs(x = \"Elevation m a.s.l\", y = \"\") +\n  guides(linetype = FALSE,\n         fill = FALSE,\n         colour = guide_legend(override.aes = list(fill = NA))) +\n  facet_wrap( ~ index, scales = \"free_y\")\n#> Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n#> \"none\")` instead.\n\n\n\n\nDiscuss restuls…\n\n9.0.2 Multivariate analysis - NMDS ordination\nIn addition to univariate descriptor of communities such as diversity indices, we might be interested in the species composition along the elevational gradient.\nA common method is non-metric multidimensional scaling (NMDS). A NMDS collapses information from multiple dimensions to a few dimensions. This allows to visualise the data more easily.\nAn NMDS can be done using the metaMDS() function form the vegan package.\n\n\ncover_fat <- comm %>%\n  select(-family, -functional_group, -c(burn_year:course)) %>%\n  arrange(year, season, month) %>%\n  pivot_wider(names_from = \"taxon\", values_from = \"cover\", values_fill = 0) %>%\n  ungroup()\n\ncover_fat_spp <- cover_fat %>% select(-(year:plot_id))\n\nset.seed(32)\nNMDS <- metaMDS(cover_fat_spp,\n                noshare = TRUE,\n                try = 30,\n                trace = 0)\n\nfNMDS <- fortify(NMDS) %>%\n  filter(Score == \"sites\") %>%\n  bind_cols(cover_fat %>% select(year:plot_id))\n\nCheck stress… (explain what it is and why it is done)\n\n\n  NMDS_1 <-  metaMDS(cover_fat_spp, noshare = TRUE, try = 30, k = 1)\n  NMDS_2 <-  metaMDS(cover_fat_spp, noshare = TRUE, try = 30, k = 2)\n  NMDS_3 <-  metaMDS(cover_fat_spp, noshare = TRUE, try = 30, k = 3)\n  NMDS_4 <-  metaMDS(cover_fat_spp, noshare = TRUE, try = 30, k = 4)\n  NMDS_5 <-  metaMDS(cover_fat_spp, noshare = TRUE, try = 30, k = 5)\n  NMDS_6 <-  metaMDS(cover_fat_spp, noshare = TRUE, try = 30, k = 6)\n\ntibble(\n    stress = c(NMDS_1$stress, NMDS_2$stress, NMDS_3$stress, NMDS_4$stress, NMDS_5$stress, NMDS_6$stress),\n    dimensions = c(1:6)) %>%\n    ggplot(aes(x = dimensions, y = stress)) +\n    geom_point()\n\n\n#> Square root transformation\n#> Wisconsin double standardization\n#> Using step-across dissimilarities:\n#> Too long or NA distances: 708 out of 21945 (3.2%)\n#> Stepping across 21945 dissimilarities...\n#> Connectivity of distance matrix with threshold dissimilarity 1 \n#> Data are connected\n#> Run 0 stress 0.3669738 \n#> Run 1 stress 0.3966017 \n#> Run 2 stress 0.5190487 \n#> Run 3 stress 0.5744689 \n#> Run 4 stress 0.4411074 \n#> Run 5 stress 0.574498 \n#> Run 6 stress 0.5139886 \n#> Run 7 stress 0.5745687 \n#> Run 8 stress 0.4332597 \n#> Run 9 stress 0.5172638 \n#> Run 10 stress 0.5745844 \n#> Run 11 stress 0.4944197 \n#> Run 12 stress 0.417065 \n#> Run 13 stress 0.5063905 \n#> Run 14 stress 0.4471289 \n#> Run 15 stress 0.5745715 \n#> Run 16 stress 0.574576 \n#> Run 17 stress 0.4223127 \n#> Run 18 stress 0.5186829 \n#> Run 19 stress 0.5078911 \n#> Run 20 stress 0.5160806 \n#> Run 21 stress 0.4569249 \n#> Run 22 stress 0.4483193 \n#> Run 23 stress 0.4329702 \n#> Run 24 stress 0.5744662 \n#> Run 25 stress 0.5744928 \n#> Run 26 stress 0.5124116 \n#> Run 27 stress 0.5167869 \n#> Run 28 stress 0.5030833 \n#> Run 29 stress 0.4654018 \n#> Run 30 stress 0.511481 \n#> *** No convergence -- monoMDS stopping criteria:\n#>     11: stress ratio > sratmax\n#>     19: scale factor of the gradient < sfgrmin\n#> Square root transformation\n#> Wisconsin double standardization\n#> Using step-across dissimilarities:\n#> Too long or NA distances: 708 out of 21945 (3.2%)\n#> Stepping across 21945 dissimilarities...\n#> Connectivity of distance matrix with threshold dissimilarity 1 \n#> Data are connected\n#> Run 0 stress 0.20073 \n#> Run 1 stress 0.2182501 \n#> Run 2 stress 0.2083237 \n#> Run 3 stress 0.2005945 \n#> ... New best solution\n#> ... Procrustes: rmse 0.006078256  max resid 0.06685748 \n#> Run 4 stress 0.2007521 \n#> ... Procrustes: rmse 0.006366959  max resid 0.06729406 \n#> Run 5 stress 0.2355802 \n#> Run 6 stress 0.2225095 \n#> Run 7 stress 0.2011206 \n#> Run 8 stress 0.214649 \n#> Run 9 stress 0.2086967 \n#> Run 10 stress 0.2082084 \n#> Run 11 stress 0.2004971 \n#> ... New best solution\n#> ... Procrustes: rmse 0.00217813  max resid 0.02930483 \n#> Run 12 stress 0.2448126 \n#> Run 13 stress 0.2004924 \n#> ... New best solution\n#> ... Procrustes: rmse 0.0009213377  max resid 0.01260201 \n#> Run 14 stress 0.2366596 \n#> Run 15 stress 0.2219288 \n#> Run 16 stress 0.2007299 \n#> ... Procrustes: rmse 0.005094979  max resid 0.06565216 \n#> Run 17 stress 0.2007521 \n#> ... Procrustes: rmse 0.005304626  max resid 0.06601554 \n#> Run 18 stress 0.2200119 \n#> Run 19 stress 0.2465379 \n#> Run 20 stress 0.201122 \n#> Run 21 stress 0.212618 \n#> Run 22 stress 0.2490223 \n#> Run 23 stress 0.2456565 \n#> Run 24 stress 0.2351948 \n#> Run 25 stress 0.2011839 \n#> Run 26 stress 0.2005931 \n#> ... Procrustes: rmse 0.002075318  max resid 0.02814701 \n#> Run 27 stress 0.2007299 \n#> ... Procrustes: rmse 0.00506658  max resid 0.06559041 \n#> Run 28 stress 0.2110259 \n#> Run 29 stress 0.2136821 \n#> Run 30 stress 0.2004925 \n#> ... Procrustes: rmse 7.2719e-05  max resid 0.0005361616 \n#> ... Similar to previous best\n#> *** Solution reached\n#> Square root transformation\n#> Wisconsin double standardization\n#> Using step-across dissimilarities:\n#> Too long or NA distances: 708 out of 21945 (3.2%)\n#> Stepping across 21945 dissimilarities...\n#> Connectivity of distance matrix with threshold dissimilarity 1 \n#> Data are connected\n#> Run 0 stress 0.1496032 \n#> Run 1 stress 0.1496028 \n#> ... New best solution\n#> ... Procrustes: rmse 0.0004109622  max resid 0.004798846 \n#> ... Similar to previous best\n#> Run 2 stress 0.1496028 \n#> ... New best solution\n#> ... Procrustes: rmse 3.385516e-05  max resid 0.0001892113 \n#> ... Similar to previous best\n#> Run 3 stress 0.1496029 \n#> ... Procrustes: rmse 8.602209e-05  max resid 0.0004481636 \n#> ... Similar to previous best\n#> Run 4 stress 0.1496026 \n#> ... New best solution\n#> ... Procrustes: rmse 0.0001241784  max resid 0.001492955 \n#> ... Similar to previous best\n#> Run 5 stress 0.1496034 \n#> ... Procrustes: rmse 0.0003495415  max resid 0.003669896 \n#> ... Similar to previous best\n#> Run 6 stress 0.1496046 \n#> ... Procrustes: rmse 0.002793576  max resid 0.03467881 \n#> Run 7 stress 0.1496048 \n#> ... Procrustes: rmse 0.002795569  max resid 0.03469251 \n#> Run 8 stress 0.1496043 \n#> ... Procrustes: rmse 0.002785784  max resid 0.03460863 \n#> Run 9 stress 0.1496042 \n#> ... Procrustes: rmse 0.002779486  max resid 0.03453958 \n#> Run 10 stress 0.149612 \n#> ... Procrustes: rmse 0.002905389  max resid 0.03510331 \n#> Run 11 stress 0.1496031 \n#> ... Procrustes: rmse 0.0002450591  max resid 0.002602491 \n#> ... Similar to previous best\n#> Run 12 stress 0.1496045 \n#> ... Procrustes: rmse 0.002794077  max resid 0.0346816 \n#> Run 13 stress 0.1496031 \n#> ... Procrustes: rmse 0.0001597965  max resid 0.001086928 \n#> ... Similar to previous best\n#> Run 14 stress 0.1496047 \n#> ... Procrustes: rmse 0.002796931  max resid 0.03470258 \n#> Run 15 stress 0.1496029 \n#> ... Procrustes: rmse 0.0001716801  max resid 0.001949172 \n#> ... Similar to previous best\n#> Run 16 stress 0.1496081 \n#> ... Procrustes: rmse 0.0007773416  max resid 0.006660007 \n#> ... Similar to previous best\n#> Run 17 stress 0.1496036 \n#> ... Procrustes: rmse 0.0003405729  max resid 0.003538791 \n#> ... Similar to previous best\n#> Run 18 stress 0.1496049 \n#> ... Procrustes: rmse 0.002655481  max resid 0.03292451 \n#> Run 19 stress 0.1496044 \n#> ... Procrustes: rmse 0.002672476  max resid 0.03315833 \n#> Run 20 stress 0.1496044 \n#> ... Procrustes: rmse 0.002830271  max resid 0.03504831 \n#> Run 21 stress 0.149603 \n#> ... Procrustes: rmse 0.000143452  max resid 0.0013587 \n#> ... Similar to previous best\n#> Run 22 stress 0.1496151 \n#> ... Procrustes: rmse 0.002946852  max resid 0.03519211 \n#> Run 23 stress 0.1496042 \n#> ... Procrustes: rmse 0.0004387517  max resid 0.004368286 \n#> ... Similar to previous best\n#> Run 24 stress 0.1496047 \n#> ... Procrustes: rmse 0.002792242  max resid 0.03466513 \n#> Run 25 stress 0.1496095 \n#> ... Procrustes: rmse 0.002869195  max resid 0.03500028 \n#> Run 26 stress 0.1496031 \n#> ... Procrustes: rmse 0.000161386  max resid 0.001007451 \n#> ... Similar to previous best\n#> Run 27 stress 0.149604 \n#> ... Procrustes: rmse 0.0003265561  max resid 0.003195434 \n#> ... Similar to previous best\n#> Run 28 stress 0.1496034 \n#> ... Procrustes: rmse 0.0003205402  max resid 0.003133215 \n#> ... Similar to previous best\n#> Run 29 stress 0.1496043 \n#> ... Procrustes: rmse 0.002784911  max resid 0.03460711 \n#> Run 30 stress 0.1496035 \n#> ... Procrustes: rmse 0.0003698297  max resid 0.003956172 \n#> ... Similar to previous best\n#> *** Solution reached\n#> Square root transformation\n#> Wisconsin double standardization\n#> Using step-across dissimilarities:\n#> Too long or NA distances: 708 out of 21945 (3.2%)\n#> Stepping across 21945 dissimilarities...\n#> Connectivity of distance matrix with threshold dissimilarity 1 \n#> Data are connected\n#> Run 0 stress 0.1236357 \n#> Run 1 stress 0.1240154 \n#> ... Procrustes: rmse 0.03150932  max resid 0.09941104 \n#> Run 2 stress 0.1241406 \n#> Run 3 stress 0.1240211 \n#> ... Procrustes: rmse 0.03230265  max resid 0.09941862 \n#> Run 4 stress 0.1236349 \n#> ... New best solution\n#> ... Procrustes: rmse 0.0001169962  max resid 0.0006613207 \n#> ... Similar to previous best\n#> Run 5 stress 0.1240922 \n#> ... Procrustes: rmse 0.008361968  max resid 0.09420276 \n#> Run 6 stress 0.1238104 \n#> ... Procrustes: rmse 0.02818918  max resid 0.1205201 \n#> Run 7 stress 0.1240505 \n#> ... Procrustes: rmse 0.0306759  max resid 0.1001498 \n#> Run 8 stress 0.1245961 \n#> Run 9 stress 0.1240572 \n#> ... Procrustes: rmse 0.0290986  max resid 0.1001645 \n#> Run 10 stress 0.1236349 \n#> ... Procrustes: rmse 0.00089162  max resid 0.007473249 \n#> ... Similar to previous best\n#> Run 11 stress 0.1238541 \n#> ... Procrustes: rmse 0.02383616  max resid 0.1284415 \n#> Run 12 stress 0.1238256 \n#> ... Procrustes: rmse 0.02317068  max resid 0.1002362 \n#> Run 13 stress 0.1240649 \n#> ... Procrustes: rmse 0.03346715  max resid 0.1028719 \n#> Run 14 stress 0.1240161 \n#> ... Procrustes: rmse 0.0118338  max resid 0.09619942 \n#> Run 15 stress 0.1237134 \n#> ... Procrustes: rmse 0.02723612  max resid 0.09894111 \n#> Run 16 stress 0.1236339 \n#> ... New best solution\n#> ... Procrustes: rmse 0.0006986775  max resid 0.004219814 \n#> ... Similar to previous best\n#> Run 17 stress 0.1237204 \n#> ... Procrustes: rmse 0.02645367  max resid 0.09898438 \n#> Run 18 stress 0.1239427 \n#> ... Procrustes: rmse 0.02043016  max resid 0.100191 \n#> Run 19 stress 0.1229504 \n#> ... New best solution\n#> ... Procrustes: rmse 0.02501793  max resid 0.1597669 \n#> Run 20 stress 0.1240791 \n#> Run 21 stress 0.1229588 \n#> ... Procrustes: rmse 0.001804713  max resid 0.01919788 \n#> Run 22 stress 0.1236982 \n#> Run 23 stress 0.1239967 \n#> Run 24 stress 0.1240594 \n#> Run 25 stress 0.1236348 \n#> Run 26 stress 0.1237123 \n#> Run 27 stress 0.1240147 \n#> Run 28 stress 0.1240213 \n#> Run 29 stress 0.12396 \n#> Run 30 stress 0.1240317 \n#> *** No convergence -- monoMDS stopping criteria:\n#>     23: no. of iterations >= maxit\n#>      7: stress ratio > sratmax\n#> Square root transformation\n#> Wisconsin double standardization\n#> Using step-across dissimilarities:\n#> Too long or NA distances: 708 out of 21945 (3.2%)\n#> Stepping across 21945 dissimilarities...\n#> Connectivity of distance matrix with threshold dissimilarity 1 \n#> Data are connected\n#> Run 0 stress 0.1014859 \n#> Run 1 stress 0.1014859 \n#> ... New best solution\n#> ... Procrustes: rmse 0.001496211  max resid 0.01341869 \n#> Run 2 stress 0.1014882 \n#> ... Procrustes: rmse 0.0003613118  max resid 0.0030562 \n#> ... Similar to previous best\n#> Run 3 stress 0.1019811 \n#> ... Procrustes: rmse 0.01013506  max resid 0.05227495 \n#> Run 4 stress 0.1015739 \n#> ... Procrustes: rmse 0.003590735  max resid 0.02819999 \n#> Run 5 stress 0.1015006 \n#> ... Procrustes: rmse 0.001874394  max resid 0.01532635 \n#> Run 6 stress 0.1018107 \n#> ... Procrustes: rmse 0.008071745  max resid 0.04308882 \n#> Run 7 stress 0.1014854 \n#> ... New best solution\n#> ... Procrustes: rmse 0.001301816  max resid 0.01229766 \n#> Run 8 stress 0.1016368 \n#> ... Procrustes: rmse 0.00415404  max resid 0.04176875 \n#> Run 9 stress 0.101771 \n#> ... Procrustes: rmse 0.005992127  max resid 0.05172668 \n#> Run 10 stress 0.101486 \n#> ... Procrustes: rmse 0.001163481  max resid 0.009342148 \n#> ... Similar to previous best\n#> Run 11 stress 0.1014844 \n#> ... New best solution\n#> ... Procrustes: rmse 0.0005162083  max resid 0.003108608 \n#> ... Similar to previous best\n#> Run 12 stress 0.1020294 \n#> Run 13 stress 0.1015629 \n#> ... Procrustes: rmse 0.003142189  max resid 0.01789825 \n#> Run 14 stress 0.1014907 \n#> ... Procrustes: rmse 0.000584355  max resid 0.005003165 \n#> ... Similar to previous best\n#> Run 15 stress 0.1014848 \n#> ... Procrustes: rmse 0.0008144449  max resid 0.007596159 \n#> ... Similar to previous best\n#> Run 16 stress 0.1014845 \n#> ... Procrustes: rmse 0.0004405542  max resid 0.004920053 \n#> ... Similar to previous best\n#> Run 17 stress 0.1012551 \n#> ... New best solution\n#> ... Procrustes: rmse 0.02773564  max resid 0.1657609 \n#> Run 18 stress 0.1021218 \n#> Run 19 stress 0.1018503 \n#> Run 20 stress 0.1014859 \n#> ... Procrustes: rmse 0.02767256  max resid 0.1646763 \n#> Run 21 stress 0.101487 \n#> ... Procrustes: rmse 0.02771247  max resid 0.1652471 \n#> Run 22 stress 0.1018845 \n#> Run 23 stress 0.1023329 \n#> Run 24 stress 0.1014867 \n#> ... Procrustes: rmse 0.02778127  max resid 0.1637971 \n#> Run 25 stress 0.1013431 \n#> ... Procrustes: rmse 0.009275203  max resid 0.05384371 \n#> Run 26 stress 0.1012622 \n#> ... Procrustes: rmse 0.006106135  max resid 0.04427436 \n#> Run 27 stress 0.1015213 \n#> ... Procrustes: rmse 0.02779551  max resid 0.1627817 \n#> Run 28 stress 0.1016594 \n#> ... Procrustes: rmse 0.02781834  max resid 0.1594333 \n#> Run 29 stress 0.1015512 \n#> ... Procrustes: rmse 0.02786594  max resid 0.1633327 \n#> Run 30 stress 0.1015087 \n#> ... Procrustes: rmse 0.0277089  max resid 0.1632642 \n#> *** No convergence -- monoMDS stopping criteria:\n#>     23: no. of iterations >= maxit\n#>      7: stress ratio > sratmax\n#> Square root transformation\n#> Wisconsin double standardization\n#> Using step-across dissimilarities:\n#> Too long or NA distances: 708 out of 21945 (3.2%)\n#> Stepping across 21945 dissimilarities...\n#> Connectivity of distance matrix with threshold dissimilarity 1 \n#> Data are connected\n#> Run 0 stress 0.0871146 \n#> Run 1 stress 0.08846572 \n#> Run 2 stress 0.08713978 \n#> ... Procrustes: rmse 0.003713778  max resid 0.02036551 \n#> Run 3 stress 0.08878503 \n#> Run 4 stress 0.08735978 \n#> ... Procrustes: rmse 0.005332886  max resid 0.0277197 \n#> Run 5 stress 0.08943071 \n#> Run 6 stress 0.08942787 \n#> Run 7 stress 0.08719705 \n#> ... Procrustes: rmse 0.003194158  max resid 0.01283403 \n#> Run 8 stress 0.08757549 \n#> ... Procrustes: rmse 0.01025835  max resid 0.04840186 \n#> Run 9 stress 0.08980633 \n#> Run 10 stress 0.08778312 \n#> Run 11 stress 0.08898063 \n#> Run 12 stress 0.08979292 \n#> Run 13 stress 0.08716465 \n#> ... Procrustes: rmse 0.002855812  max resid 0.01809449 \n#> Run 14 stress 0.08880298 \n#> Run 15 stress 0.08992085 \n#> Run 16 stress 0.08726124 \n#> ... Procrustes: rmse 0.006536252  max resid 0.03952786 \n#> Run 17 stress 0.08927162 \n#> Run 18 stress 0.08747088 \n#> ... Procrustes: rmse 0.009478915  max resid 0.04331799 \n#> Run 19 stress 0.08725912 \n#> ... Procrustes: rmse 0.006182781  max resid 0.04046836 \n#> Run 20 stress 0.08713052 \n#> ... Procrustes: rmse 0.00294201  max resid 0.01589794 \n#> Run 21 stress 0.08711406 \n#> ... New best solution\n#> ... Procrustes: rmse 0.003584975  max resid 0.02486928 \n#> Run 22 stress 0.08744816 \n#> ... Procrustes: rmse 0.008395644  max resid 0.04549463 \n#> Run 23 stress 0.08718053 \n#> ... Procrustes: rmse 0.005427267  max resid 0.03738844 \n#> Run 24 stress 0.08721509 \n#> ... Procrustes: rmse 0.006264433  max resid 0.03730534 \n#> Run 25 stress 0.08721308 \n#> ... Procrustes: rmse 0.00452053  max resid 0.01489785 \n#> Run 26 stress 0.08719441 \n#> ... Procrustes: rmse 0.005963353  max resid 0.02706668 \n#> Run 27 stress 0.08711333 \n#> ... New best solution\n#> ... Procrustes: rmse 0.002752416  max resid 0.01551721 \n#> Run 28 stress 0.08715922 \n#> ... Procrustes: rmse 0.003436136  max resid 0.02777786 \n#> Run 29 stress 0.08712261 \n#> ... Procrustes: rmse 0.002925042  max resid 0.02545719 \n#> Run 30 stress 0.08713603 \n#> ... Procrustes: rmse 0.00156582  max resid 0.007586865 \n#> ... Similar to previous best\n#> *** Solution reached\n\n\n\n\nDiscuss the results of the stress plot and what desicion is taken. How many dimesions are chosen.\nVisualise\nThe output of an ordination can be visualised.\n\n\nfNMDS %>%\n  as_tibble() %>%\n  mutate(treatment = factor(treatment, levels = c(\"C\", \"B\", \"NB\")),\n         site = factor(site, levels = c(\"WAY\", \"ACJ\", \"PIL\", \"TRE\", \"QUE\", \"OCC\")),\n         season = if_else(season == \"dry_season\",\n                          \"Dry season\",\n                          \"Wet season\")) %>%\n  ggplot(aes(x = NMDS1, y = NMDS2, colour = site, shape = treatment)) +\n  geom_point() +\n  scale_colour_manual(\"Site\", values = puna_site_colour$colour) +\n  scale_shape_manual(\"Treatment\", values=c(16, 5, 6)) +\n  facet_wrap(~ season)\n\n\n\n\nDiscuss results."
  },
  {
    "objectID": "10_bootstrap.html",
    "href": "10_bootstrap.html",
    "title": "\n10  Bootstrapping method\n",
    "section": "",
    "text": "This vignette explains how to use the traitstrap package (Telford et al). For more details on the methods see Maitner et al.\nFirst of all, relax and turn on some music. We have prepared the traitstrap playlist for you!\n\n10.0.1 The aim of traitstrap\nTrait distributions can be used to infer the importance of community assembly processes and the role of climate drivers in shaping species and community responses to climate change. Community ecology has typically focused on the mean, however the higher moments (variance, skewness, and kurtosis) of trait distributions can reveal information about the various processes shaping species diversity.\n\n\n\n\nTrue distribution, mean and higher moments.\n\n\n\n\nMeasuring trait distributions is often difficult and time-consuming as it requires information on measuring trait values of all individuals present. Sampling protocols often limit sampling to a non-representative subset of the community, or rely upon species-level average traits values calculated in other locations or across many locations.\nTraditionally the moments of trait distributions have been estimated using weighting approaches that rely on the average traits of species weighted by some measure of abundance within the community. Such community-weighted trait moments methods assume that a species’ trait expression can be adequately represented by the mean, ignoring intraspecific trait variation.\nTo more accurately estimate local trait distributions, trait sampling should thus occur both across multiple individuals within each species, and across multiple locations or experimental treatments across the extent of the study in order to capture both inter- and intra-specific variability.\n\n\n\n\nCommunity weighted mean versus bootstrapping method.\n\n\n\n\nTraitstrap is an R package to estimate the moments of community trait distributions using a bootstrapping approach. Further, this package uses a hierarchical sampling design, which allows accounting for incomplete trait collections, traits from different spatial or temporal levels (e.g. local traits vs. databases), taxonomic hierarchies (e.g., species vs genus) and experimental designs (e.g., multiple sites, or treated vs. control sampling units).\nThe package has three main functions:\n\n\ntrait imputation function which allows to account for intraspecific trait variation and hierarchical sampling design.\na resample method using bootstrapping (parametric or nonparametric method) to calculate community weighted mean and happy moments (variance, skewness and kurtosis).\na summary function that summarizes the trait moments and calculates confidence intervals.\n\nNote that for this tutorial we are calling the mean and the higher moments the happy moments :-)\n\n10.0.2 The data\nFor this vignette we will use part of a vascular plant dataset from two sites near Longyearbyen on Svalbard. The data was collected during the Plant Functional Trait Course in 2018 and contains data on the plant community composition and functional traits. For more details see this GitHub repo\nNote that some of the species names have been adapted.\n\n\n\n\n10.0.3 Organize your data\nTo run traitstrap two datasets are required:\n\none dataset with information on abundance (e.g. biomass, size, cover, etc.) of the community, which is used to weight species traits by abundance in the community.\none dataset with the traits for each species (or as many species and individuals you have data for) in your community.\n\nThe datasets need to be organized in a tidy and long format and certain columns (see below) are required, but the naming of these columns are up to the user.\nLet us have a look at these datasets in an example.\nThe community data should have information the abundance of species in the community. This dataset will be used to weigh the traits by species abundance. Note that abundance can also be cover, size, biomass, or something similar.\nIn this example the contains species names (e.g. Taxon), cover of each species per plot (e.g. Cover) and two columns with information about the hierarchy (i.e. Site and PlotID).\n\n#> # A tibble: 110 × 4\n#>    Taxon             Cover Site  PlotID\n#>    <chr>             <dbl> <chr> <chr> \n#>  1 alopecurus ovatus   0.5 1     B     \n#>  2 alopecurus ovatus   1   1     C     \n#>  3 alopecurus ovatus   1   1     D     \n#>  4 alopecurus ovatus   2   1     F     \n#>  5 alopecurus ovatus   0.1 1     G     \n#>  6 bistorta vigdis    10   1     A     \n#>  7 bistorta vigdis    25   1     B     \n#>  8 bistorta vigdis    10   1     C     \n#>  9 bistorta vigdis     2   1     D     \n#> 10 bistorta vigdis     1   1     F     \n#> # … with 100 more rows\n\nThe trait data should contain information about traits and trait values for as many species and individuals in the community data as possible. The data should be organized in the same way as the community data and should have corresponding columns. In this example the trait data contains Taxon, Site and PlotID as well as Trait and Value.\n\n#> # A tibble: 749 × 5\n#>    Taxon                   Site  PlotID Trait         Value\n#>    <chr>                   <chr> <chr>  <chr>         <dbl>\n#>  1 saxifraga oppositifolia 1     A      Wet_Mass_g 0.000695\n#>  2 bistorta vigdis         1     C      Wet_Mass_g 0.0105  \n#>  3 festuca rubra           2     C      Wet_Mass_g 0.00724 \n#>  4 bistorta vigdis         1     C      Wet_Mass_g 0.0189  \n#>  5 equisetum arvense       1     E      Wet_Mass_g 0.270   \n#>  6 bistorta vigdis         1     B      Wet_Mass_g 0.0231  \n#>  7 luzula confusa          1     F      Wet_Mass_g 0.0135  \n#>  8 alopecurus ovatus       1     G      Wet_Mass_g 0.0234  \n#>  9 alopecurus ovatus       1     G      Wet_Mass_g 0.0300  \n#> 10 alopecurus ovatus       1     C      Wet_Mass_g 0.0267  \n#> # … with 739 more rows\n\n\n10.0.4 Trait imputation\nThe trait_impute function uses a hierarchical sampling design, which allows to account for incomplete trait collections, traits from different spatial or temporal levels (i.e. local traits vs. databases), different taxonomic resolution and/or experimental design.\nThe first two mandatory arguments in the function are the two datasets: comm and traits\nThe next four arguments are also mandatory and refer to specific columns in the trait or community dataset:\n\n\nabundance which is the abundance of your species in your community dataset. This can be abundance, cover, biomass, or size, etc.\n\ntaxon_col is the column in your community and trait data that define the species.\n\ntrait_col is the column in your trait data that defines the traits.\n\nvalue_col is the column in your trait data that defines the trait values.\n\nAll the other arguments are not mandatory.\nWith scale_hierarchy you can define the levels at which the traits have been collected and the order of trait imputation starting with the highest level (e.g. global database, regional, site, plot). In the example below we have the levels Site and PlotID, starting with the highest level.\nThe trait_impute function will choose if available a trait value from the lowest level, i.e. species X from plot A in site 1. If no trait value is available from that level (plot A, site 1), it will other groups in the same level and choose a trait value from species X from plot B or C at site 1. If there is no trait available, it will move up the hierarchy to the next level and choose trait values from species X from other sites (site 2, 3, etc.).\nThe argument min_n_in_samples allows users to define the minimum number in samples that are chosen at each level. If the minimum number is not reached (i.e. there are only 3 trait values at a specific level), trait values from the next higher level will be imputed, to avoid sampling the same individual several times, which could result in unrealistic variances. The default minimum number of samples is 5.\nIn the other_col argument other grouping variables in the community dataset can be defined and will be kept after the trait imputation.\n\ntrait_imputation <- trait_impute(\n    # input data (mandatory)\n    comm = community,\n    traits = trait,\n    \n    # specifies columns in your data (mandatory)\n    abundance_col = \"Cover\",\n    taxon_col = \"Taxon\",\n    trait_col = \"Trait\",\n    value_col = \"Value\",\n    \n    # specifies sampling hierarchy\n    scale_hierarchy = c(\"Site\", \"PlotID\"),\n    \n    # min number of samples\n    min_n_in_sample = 9\n  )\ntrait_imputation\n#> # A tibble: 4,007 × 12\n#> # Groups:   global, Site, PlotID, Trait [28]\n#>    Taxon  Cover Site  PlotID global sum_abun Trait   Value n_sample weight level\n#>    <chr>  <dbl> <chr> <chr>  <chr>     <dbl> <chr>   <dbl>    <int>  <dbl> <ord>\n#>  1 festu…     1 1     A      global     38.2 Wet_… 0.00724       11 0.0909 glob…\n#>  2 festu…     1 1     A      global     38.2 Wet_… 0.0160        11 0.0909 glob…\n#>  3 festu…     1 1     A      global     38.2 Wet_… 0.00529       11 0.0909 glob…\n#>  4 festu…     1 1     A      global     38.2 Wet_… 0.0154        11 0.0909 glob…\n#>  5 festu…     1 1     A      global     38.2 Wet_… 0.0066        11 0.0909 glob…\n#>  6 festu…     1 1     A      global     38.2 Wet_… 0.00637       11 0.0909 glob…\n#>  7 festu…     1 1     A      global     38.2 Wet_… 0.00491       11 0.0909 glob…\n#>  8 festu…     1 1     A      global     38.2 Wet_… 0.0132        11 0.0909 glob…\n#>  9 festu…     1 1     A      global     38.2 Wet_… 0.0233        11 0.0909 glob…\n#> 10 festu…     1 1     A      global     38.2 Wet_… 0.0115        11 0.0909 glob…\n#> # … with 3,997 more rows, and 1 more variable: max_n_in_sample <int>\n\nTraitstrap also allows to include taxonomy and experimental design in the trait imputation step.\nWith the argument taxon_col the taxonomic hierarchy for sampling can be defined. This means if traits for a specific species are not available, trait values from the same genus will be imputed. For this a list of the taxonomic hierarchy has to be defined (e.g. “Taxon”, “Genus”). Note that traits from species of the same genus can have very different traits and it might not be meaningful to impute these traits. Therefore, you should always check the trait distributions for the same genus before using taxonomic trait imputation.\nThe argument treatment_col allows to incorporate an experimental design where traits are imputed from the same experimental treatment or the first factor level, which is assumed to be the control. Therefore, it is important to order the levels of a treatment in the right order, i.e. the first level has to be the control. The imputation step can be defined at certain level using the treatment_level argument. Depending on the experimental design it might make sense to impute traits at a certain level, e.g. block or site.\nHere is an example how to include taxonomy and experimental design in the trait imputation function (code not run).\n\ntrait_imputation2 <- trait_impute(\n    comm = community,\n    traits = trait,\n    \n    abundance_col = \"Cover\",\n    \n    # defining taxonomic hierarchy\n    taxon_col = c(\"Taxon\", \"Genus\"),\n    \n    trait_col = \"Trait\",\n    value_col = \"Value\",\n    \n    scale_hierarchy = c(\"Site\", \"PlotID\"),\n    min_n_in_sample = 3\n    \n    # specifying experimental design\n    treatment_col = \"Treatment\",\n    treatment_level = \"Site\",\n  )\n\n\n10.0.5 Nonparametric bootstrapping\nThe output of the trait imputation function is then used to do a nonparametric bootstrapping using the trait_np_bootstrap function.\nNonparametric bootstrapping is a resampling method to estimate the trait moments. The traits are re-sampled in proportion to their weight in the community (e.g. by the abundance of the species).\nThe trait values across all individuals in a community are resampled n times (sample_size; the default is 200) to incorporate the full spectrum of trait variation, generating n number (nrep; the default is 100) of trait distributions.\nFrom these trait distributions the happy moments are estimated: mean, variance, skewness and kurtosis.\nThis function also allows to extract raw distributions by setting the argument raw = TRUE. The raw data can be useful for visualizing the trait distributions. If the raw data is extracted, nrep is forced to 1 to avoid memory issues.\n\n# run nonparametric bootstrapping\nnp_bootstrapped_moments <- trait_np_bootstrap(\n  trait_imputation, \n  nrep = 200\n  )\nnp_bootstrapped_moments\n#> # A tibble: 5,600 × 9\n#> # Groups:   global, Site, PlotID [14]\n#>    n     global Site  PlotID Trait             mean   variance skewness kurtosis\n#>    <chr> <chr>  <chr> <chr>  <chr>            <dbl>      <dbl>    <dbl>    <dbl>\n#>  1 1     global 1     A      Plant_Height_cm 1.72    2.79         2.76     8.23 \n#>  2 1     global 1     A      Wet_Mass_g      0.0124  0.0000764    1.20     1.76 \n#>  3 1     global 1     B      Plant_Height_cm 1.76    2.77         2.44     6.85 \n#>  4 1     global 1     B      Wet_Mass_g      0.0126  0.0000627    1.09     1.47 \n#>  5 1     global 1     C      Plant_Height_cm 1.72    2.11         2.59     7.15 \n#>  6 1     global 1     C      Wet_Mass_g      0.0147  0.000100     3.43    20.4  \n#>  7 1     global 1     D      Plant_Height_cm 1.82    4.58         2.45     5.44 \n#>  8 1     global 1     D      Wet_Mass_g      0.0110  0.0000336    0.856    0.550\n#>  9 1     global 1     E      Plant_Height_cm 7.35   19.1          0.255   -0.544\n#> 10 1     global 1     E      Wet_Mass_g      0.0154  0.000252     2.94     8.25 \n#> # … with 5,590 more rows\n\nOne advantage of using a bootstrapping approach, is that we get much more than a mean trait value. We can also estimate the variance and other moments of these trait distributions. In traitstrap happy moments can be summarized and the confidence intervals calculated using the trait_summarise_boot_moments function. The input variable for this function is the output from the nonparametric bootstrapping function (or the parametric bootstrapping function, see below).\nThe confidence interval can be calculated parametrically, using the mean and standard deviation, or nonparametrically using quantiles. The default is using the mean and standard deviation (parametric = TRUE) with one standard deviation around each trait moment (sd_mult = 1). For the nonparametric approach the default is a 0.95 confidence level.\n\n# summarizes bootstrapping output\nsum_boot_moment <- trait_summarise_boot_moments(\n  np_bootstrapped_moments\n  )\nsum_boot_moment\n#> # A tibble: 28 × 17\n#> # Groups:   global, Site, PlotID [14]\n#>    global Site  PlotID Trait           n   mean ci_low_mean ci_high_mean     var\n#>    <chr>  <chr> <chr>  <chr>       <int>  <dbl>       <dbl>        <dbl>   <dbl>\n#>  1 global 1     A      Plant_Heig…   200 1.71        1.59         1.83   2.62e+0\n#>  2 global 1     A      Wet_Mass_g    200 0.0121      0.0116       0.0127 6.60e-5\n#>  3 global 1     B      Plant_Heig…   200 1.74        1.64         1.85   2.58e+0\n#>  4 global 1     B      Wet_Mass_g    200 0.0137      0.0131       0.0143 6.91e-5\n#>  5 global 1     C      Plant_Heig…   200 1.71        1.62         1.81   1.84e+0\n#>  6 global 1     C      Wet_Mass_g    200 0.0148      0.0142       0.0155 1.27e-4\n#>  7 global 1     D      Plant_Heig…   200 1.84        1.69         2.00   4.47e+0\n#>  8 global 1     D      Wet_Mass_g    200 0.0117      0.0112       0.0123 5.03e-5\n#>  9 global 1     E      Plant_Heig…   200 7.10        6.80         7.40   1.70e+1\n#> 10 global 1     E      Wet_Mass_g    200 0.0161      0.0149       0.0173 2.75e-4\n#> # … with 18 more rows, and 8 more variables: ci_low_var <dbl>,\n#> #   ci_high_var <dbl>, skew <dbl>, ci_low_skew <dbl>, ci_high_skew <dbl>,\n#> #   kurt <dbl>, ci_low_kurt <dbl>, ci_high_kurt <dbl>\n\n\n10.0.6 Parametric bootstrapping\nTraitstrap also offers the option to run a parametric bootstrapping.\nThe trait_fit_distributions function fits parametric distributions for each species-by-trait combination at the finest scale of the user-supplied hierarchy. This function takes as input:\n\nan object of class imputed traits (as produced by the function trait_impute), and\nthe type of distribution to be fitted.\n\nEither a single distribution type can be used for all traits, or traits can be assigned specific distributions types by supplying the function with a named list of traits (e.g. list(height = \"normal\", mass = \"lognormal\")).\nCurrently the function supports normal, log-normal, and beta (values between 0 and 1) distributions.\nThe function returns a dataframe containing fitted distribution parameters.\n\n# fit distributions\nfitted_distributions <- trait_fit_distributions(\n  imputed_traits = trait_imputation,\n  distribution_type = \"lognormal\"\n  )\n#> Warning in .data[[\"Trait\"]] == names(distribution_type)[distribution_type == :\n#> longer object length is not a multiple of shorter object length\nfitted_distributions\n#> # A tibble: 202 × 15\n#> # Groups:   global, Site, PlotID, Trait, Taxon, Cover, n_sample [202]\n#>    global Site  PlotID Trait  Taxon Cover n_sample distribution_ty…  parm1 parm2\n#>    <chr>  <chr> <chr>  <chr>  <chr> <dbl>    <int> <chr>             <dbl> <dbl>\n#>  1 global 1     A      Plant… bist…  10         28 lognormal         0.328 0.517\n#>  2 global 1     A      Plant… drya…   0.1        9 lognormal         1.04  0.704\n#>  3 global 1     A      Plant… fest…   1         11 lognormal         1.61  0.377\n#>  4 global 1     A      Plant… luzu…   0.5       15 lognormal         1.50  0.325\n#>  5 global 1     A      Plant… luzu…   1         20 lognormal         0.588 0.459\n#>  6 global 1     A      Plant… sali…  20         44 lognormal        -0.138 0.931\n#>  7 global 1     A      Plant… saxi…   2          6 lognormal         1.13  0.469\n#>  8 global 1     A      Plant… saxi…   2          2 lognormal         0.693 0    \n#>  9 global 1     A      Plant… sile…   1          3 lognormal        -0.221 0.277\n#> 10 global 1     A      Wet_M… bist…  10         29 lognormal        -4.06  0.454\n#> # … with 192 more rows, and 5 more variables: sd1 <lgl>, sd2 <lgl>, ks <dbl>,\n#> #   cvm <dbl>, ad <dbl>\n\n\n# fit several types of distributions\nfitted_distributions <- trait_fit_distributions(\n  imputed_traits = trait_imputation,\n  distribution_type = list(Plant_Height_cm = \"normal\", Wet_Mass_g = \"lognormal\")\n  )\nfitted_distributions\n\nThe trait_parametric_bootstrap function is a parametric analogue of the trait_np_bootstrap function. It takes in fitted trait distributions produced by trait_fit_distributions and randomly samples from among the fitted distributions proportionally to species abundances in the community.\nAs with trait_np_bootstrap, the number of samples per replicated draw are specified with the parameter sample_size, and the number of replicated draws is specified by the parameter nrep. The argument raw allows to extract raw distributions (see above).\n\n# run parametric bootstrapping\np_bootstrapped_moments <- trait_parametric_bootstrap(\n    fitted_distributions = fitted_distributions, \n    nrep = 200\n    )\np_bootstrapped_moments\n#> # A tibble: 5,600 × 9\n#> # Groups:   global, Site, PlotID, Trait [28]\n#>    n     global Site  PlotID Trait             mean   variance skewness kurtosis\n#>    <chr> <chr>  <chr> <chr>  <chr>            <dbl>      <dbl>    <dbl>    <dbl>\n#>  1 1     global 1     A      Plant_Height_cm 1.70    3.15         3.00    12.2  \n#>  2 1     global 1     A      Wet_Mass_g      0.0124  0.0000831    1.67     4.18 \n#>  3 1     global 1     B      Plant_Height_cm 1.59    2.45         2.08     4.09 \n#>  4 1     global 1     B      Wet_Mass_g      0.0128  0.0000608    1.23     1.91 \n#>  5 1     global 1     C      Plant_Height_cm 1.81    2.44         2.84     9.52 \n#>  6 1     global 1     C      Wet_Mass_g      0.0160  0.000175     5.63    44.7  \n#>  7 1     global 1     D      Plant_Height_cm 1.90    4.79         2.15     4.97 \n#>  8 1     global 1     D      Wet_Mass_g      0.0123  0.0000489    1.81     5.56 \n#>  9 1     global 1     E      Plant_Height_cm 7.03   15.1          0.220    0.322\n#> 10 1     global 1     E      Wet_Mass_g      0.0174  0.000437     4.55    30.8  \n#> # … with 5,590 more rows\n\nThe output of trait_parametric_bootstrap can be summarized using trait_summarize_boot_moments (see above).\n\n10.0.7 Extracting raw distributions\nIn traitstrap both the parametric and nonparametric bootstrapping functions allow returning raw trait distributions.\n\n# run nonparametric bootstrapping\nraw_dist_np <- trait_np_bootstrap(\n  trait_imputation,\n  raw = TRUE\n  )\nraw_dist_np\n#> # A tibble: 5,600 × 13\n#> # Groups:   global, Site, PlotID, Trait [28]\n#>    n     Taxon    Cover Site  PlotID global sum_abun Trait Value n_sample weight\n#>    <chr> <chr>    <dbl> <chr> <chr>  <chr>     <dbl> <chr> <dbl>    <int>  <dbl>\n#>  1 1     salix p…    20 1     A      global     38.2 Plan…   0.8       44  0.455\n#>  2 1     salix p…    20 1     A      global     38.2 Plan…   1.1       44  0.455\n#>  3 1     saxifra…     2 1     A      global     38.2 Plan…   5.6        6  0.333\n#>  4 1     bistort…    10 1     A      global     38.2 Plan…   1.5       28  0.357\n#>  5 1     saxifra…     2 1     A      global     38.2 Plan…   2          2  1    \n#>  6 1     salix p…    20 1     A      global     38.2 Plan…   0.9       44  0.455\n#>  7 1     salix p…    20 1     A      global     38.2 Plan…   0.4       44  0.455\n#>  8 1     bistort…    10 1     A      global     38.2 Plan…   1         28  0.357\n#>  9 1     salix p…    20 1     A      global     38.2 Plan…   0.7       44  0.455\n#> 10 1     salix p…    20 1     A      global     38.2 Plan…   1         44  0.455\n#> # … with 5,590 more rows, and 2 more variables: level <ord>,\n#> #   max_n_in_sample <int>\n\nThe raw data can be useful for visualizing the trait distributions.\nUse colour and facets to separate between the different traits, hierarchies and treatments.\n\nggplot(raw_dist_np, aes(x = log(Value), fill = Site)) +\n  geom_density(alpha = 0.4) +\n  scale_fill_viridis_d(end = 0.9, option = \"plasma\") +\n  labs(x = \"log(trait value)\") +\n  facet_wrap( ~ Trait, scales = \"free\")\n\n\n\n\n\n10.0.8 Check your data\nTraitstrap has a couple of functions to check the data.\nThe coverage_plot function shows the trait coverage of the community for each level. Basically, this function summarizes from which level the traits are imputed, and how much coverage of the community is reached.\nBased on simulations, we recommend to collect traits for at least 80% of the community cover (Maitner et al. in prep).\n\n# show coverage plot\nautoplot(trait_imputation) + \n  theme(axis.text.x = element_text(size = 8, angle = 90, vjust = 0.5))\n\n\n\n\nAnother important information is to know of which taxa traits are missing. This can be useful if the data sampling is not finished and you want to know which species should be sampled. The function also tells you the maximal abundance of each missing species, and gives you useful information if the missing species are abundant or rare.\nTraitstrap has a function trait_missing which gives you a table with all missing values.\n\n# list missing traits\ntrait_missing(imputed_trait = trait_imputation,\n              comm = community)\n#> # A tibble: 20 × 3\n#> # Groups:   Taxon [20]\n#>    Taxon                      max_abun n_traits\n#>    <chr>                         <dbl>    <int>\n#>  1 alopecurus ovatus               2          2\n#>  2 bistorta vigdis                25          2\n#>  3 calamagrostis neglecta         60          2\n#>  4 cassiope tetragona              5          2\n#>  5 dryas octopetala               20          2\n#>  6 enquistetum scirpoides          2          2\n#>  7 festuca rubra                   1          2\n#>  8 juncus biglumis                 0.5        1\n#>  9 luzula confusa                  5          2\n#> 10 luzula nivalis                  5          2\n#> 11 maitneranthes hieracifolia      0.5        1\n#> 12 oxyria tanyna                   2          2\n#> 13 poa pratensis                   1          2\n#> 14 salix polaris                  43          2\n#> 15 saxifraga hirculus              2          2\n#> 16 saxifraga oppositifolia         2          2\n#> 17 silene acaudis                  1          2\n#> 18 stelfordaria humifusa           0.5        1\n#> 19 stellaria longipes              0.1        1\n#> 20 trisetum spicatum               3          2"
  }
]